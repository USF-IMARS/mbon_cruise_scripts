---
title: "NASA-HPLC Sample Submission Form for Analysis"
author: "Sebastian Di Geronimo"
date: "2023-05-02"
format: html
---

# 1.0 ---- Info ----

This file loads cruise metadata for HPLC and converts to the necessary format
used in the NASA-HPLC sample submission file before sending physical samples to 
Crystal Thomas at NASA for processing.

TODO: add way to check `hplc_progress_pres_abs.xlsx` at:
<https://usf.app.box.com/file/1203915391640>

# 2.0 ---- Setup ----

## 2.1 Load Libraries 
```{r setup}
if (!nzchar(system.file(package = "librarian"))) 
  install.packages("librarian")

librarian::shelf(
  quiet = TRUE,
  librarian, conflicted, ggplot2, tibble, tidyr, readr, purrr, dplyr, stringr,
  forcats, lubridate, glue, fs, magrittr, here,
  # broom # optional
  
  # additional
  openxlsx, hms, janitor
)

# shelf(conflicted) # may be needed if won't allow loading of certain packages

conflicts_prefer(
  dplyr::filter(), 
  dplyr::select()
  )

source(here("scripts", "misc_functions.R"))
```

## 2.2 ---- Edit: Info ----


This info is from the NASA intake form, sent in previously

You may edit the grant name, number and the person to contact.

```{r grant-info}
source(here(".Rprofile"))

grant_info <-
  list(
  info = rbind(
    # grant name
    str_c("The Southeast US Marine Biodiversity Observation Network (MBON): ",
          "Toward Operational Marine Life Data for Conservation and ",
          "Sustainability"),
    
    # grant number
    "80NSSC22K1779",
    
    # contact
    "Sebastian Di Geronimo, sebastian15@usf.edu"
  ),
  
  # PIs last name
  last_nm = "Muller-Karger"
  
  )
```


## 2.3 File Paths


Path:
- Sample Info Template
  - "HPLC_SampleInfo_template_rev2019.xlsx"
  - from NASA SeaBASS
  - a form to input metadata before sending samples for analysis
  
- Cruise metadata
  - all cruise metadata through time
  - you should filter either by cruise ID or specific dates

```{r file-path}
# path to sample submission template
# looks like <HPLC_SampleInfo_template_rev2019.xlsx>
template <-
  here("data") %>%
  dir_ls(
  regexp      = "^[^~]*sampleinfo.*", 
  type        = "file",
  ignore.case = TRUE) %>%
  str_subset("ignore", negate = TRUE)

# path to cruise metadata
metadata <-
  here(cloud_dir) %>%
  dir_ls(regexp = "imars_inventory_chl_hplc_cdom") %>%
  str_subset("~", negate = TRUE) %>%
  read.xlsx(
    sheet = "sample_meta_data",
    detectDates = FALSE
    ) %>%
  filter(str_detect(sample_type, "(?i)hplc"))  %>%
  mutate(
    date      = excel_numeric_to_date(date_mm_dd_yy),
    date_time = excel_numeric_to_date(date_time, include_time = TRUE, tz = "GMT"),
    time      = hms::as_hms(sample_collection_time_gmt),
    datetime  = ymd_hms(str_c(date, time), truncated = 3),
    station   = str_remove(station, "\\.0$"),
    .before   = date_mm_dd_yy
  ) %T>% print()


# select cruise IDs for submission
# if you want to select by cruise, add names in `str_subset()`
cruise_id <- 
  metadata %$% 
  unique(cruise_id) #%>%
  # July 2023 filtered cruise sent 
  # str_subset(str_c("(W[SB]|H)2[1-3]", "WS15264", "WS15320", "WS16319", sep = "|")) %>%
  # str_subset(str_c("WS21093", "WS21032", sep = "|"), negate = TRUE) 
  
  # Edit here: ====
  # str_subset(str_c("<edit>", sep = "|"), negate = TRUE) 


# filter metadata to match cruise IDs
metadata_filt <-
  metadata %>%
  # filter(str_detect(.data$cruise_id, str_c(.env$cruise_id, collapse = "|"))) 
  # September 2023
  filter(datetime > as_date("2023-09-01"))
```

## 2.4 Extract Column Locations for Grant Info


This locates the cell locations within the `template` to add the grant info and
the metadata.


```{r cell-locations}
grant_info$sheet_nm <- getSheetNames(template)

# row for adding metadata
grant_info$loc <-
  which(
    read.xlsx(
      template,
      sheet         = grant_info$sheet_nm,
      colNames      = FALSE,
      skipEmptyRows = FALSE,
    ) == "PI",
    arr.ind = TRUE
  )

# column names to use
grant_info$col_names <- 
  read.xlsx(
    template,
    sheet         = grant_info$sheet_nm,
    startRow      = grant_info$loc[1],
    skipEmptyCols = FALSE
  ) %>%
  names()

# location to add grant info
grant_info$grant_loc <-
  which(
    read.xlsx(
      template,
      sheet         = grant_info$sheet_nm,
      colNames      = FALSE,
      skipEmptyCols = FALSE,
    ) == "Project:",
    arr.ind = TRUE
  )
```



## 2.5 Set Water Body for Each Station

Add new stations as needed in the correct region:
- Florida Keys
- West Florida Shelf
- Southwest Florida Shelf

NOTE: the regions may change 

```{r water-body}
water_body <- list(
  "Florida Keys" = 
    c(
      1:18, 
      seq(9.1, 9.9, by = 0.1),
      "9B", "24", "LK", "MR", "WS", "21.5", "PLUME"
  ),
  "Southwest Florida Shelf" = 
    c(
      30:68,
      seq(57.1, 57.3, by = 0.1),
      "KW1", "KW2", "KW4"
  ),
  "West Florida Shelf" = c(
    "Z04-068", "CBH", "NBH", "EB1",
    as.vector(outer(
      c("AMI", "V", "TB", "CW", "L", "GP", "RP", "ROME", "CAL", "BG", "CORE-"),
      c(1:12),
      str_c
    ))
  )
) %T>% print()
```
# 3.0 ---- Convert Convert Format to NASA Sample Submission Form ----


## 3.1 Info: Required Column Names

This part will take the current format and convert it to the required format.

This info is for the user to know what is being changed.

---- *Required Format*
hplc_gsfc_id
X2
PI
sample
cruise
indicate.if.filters.are.replicates
volfilt
station
bottle
depth
water_depth
name.of.water.body
year
month
day
sdy
time
lon
lat
filter.type
filter.diameter.(mm)
filter.storage.before.shipment.to.GFC
other
other   

---- *Current Format*
base
cruise_id
year
identifier
date_mm_dd_yy
station
lon
lat
sample_collection_time_gmt
date_time
depth_m
sample_type
vol_ml
notes
sample_number
collector
max_depth



## 3.2 Convert Metadata to `SampleInfo_template`


```{r format-info}
metadata_filt

meta_format <-
  metadata_filt %>%
  mutate(
    .keep        = "none",
    .after       = 0,
    hplc_gsfc_id = NA_character_,
    X2           = NA_character_,
    PI           = "Muller-Karger, Frank",
    sample       = identifier,
    cruise       = cruise_id,
    indicate.if.filters.are.replicates = NA_character_,
    volfilt     = vol_ml,
    station,
    bottle      = -9999,
    depth       = depth_m,
    water_depth = max_depth,
    name.of.water.body = NA_character_,
    year        = year(date),
    month       = month(date, label = TRUE, abbr = TRUE),
    day         = day(date),
    sdy         = yday(date),
    time,
    time        = round_hms(time, digits = 0),
    time        = str_remove_all(time, ":"),
    time        = str_sub(time, end = 4),
    lon,
    lat,
    filter.type = "GF/F",
    `filter.diameter.(mm)` = "25 mm",
    filter.storage.before.shipment.to.GFC = "-80C",
    # other,
    # other,
  ) %>%
  
  # relocate columns
  select(contains(grant_info$col_names)) %>%
  
  # add water body names
  mutate(
    name.of.water.body = case_match(
      station,
      water_body[[1]] ~ names(water_body)[1],
      water_body[[2]] ~ names(water_body)[2],
      water_body[[3]] ~ names(water_body)[3],
      .default = NA_character_
    ),
    
    # add depth if NA
    depth = if_else(is.na(depth), 1, depth),
  ) %>%
  
  # add water column depth if NA using all stations and taking the median
  mutate(
    .by = station,
    water_depth = if_else(!is.na(water_depth), water_depth,
      median(water_depth, na.rm = TRUE)
    )
  ) %>%
  
  # arrange by time
  arrange(year, month, nchar(sample), sample) %T>%
  print()

unique(meta_format$cruise)
```
# 4.0 ---- Check Information Before Sending ----

## 4.1 Plot: Downlaod and Load Base Map

Loads: 
1. topography
  - Topography, ETOPO1, 0.0166667 degrees, Global (longitude -180 to 180), 
    (Ice Sheet Surface) from https://coastwatch.pfeg.noaa.gov/erddap/griddap/

2. land mass
  -Global Self-consistent, Hierarchical, High-resolution Geography Database 
   (GSHHG) from https://www.ngdc.noaa.gov/mgg/shorelines/


```{r load-base-map}
if (exists("base_plt")) {
  cli::cli_alert_info("{.var base_plot} is already loaded!")
} else {
  
  # scripts to download and create maps
  source(here("scripts", "map_files_dwnlod.R"))
  # fixes issue with reading raster file using decimal degrees
  sf::sf_use_s2(FALSE)

  # path to base map files
  map_loc <- here("data", "map_shp")

  # spatial extent
  exnt <- c(
    xmin = -84, # West
    xmax = -80, # East
    ymin = 24, # South
    ymax = 28.5 # North
  )

  # download topography (.nc) and coastline (.shp)
  world_download(
    path_land  = map_loc,
    path_topo  = map_loc,
    extent     = exnt,
    use_suffix = NULL
  )

  # select and read coastline file from GSHHS then crop
  # load maps
  map_obj <-
    load_map_obj(
      .map_coast = map_loc,
      .map_state = NULL,
      .map_bath  = NULL,
      .map_file  = "etopo1.nc",
      .extent    = exnt
    )

  # Plot Base Map with larger degree extent
  deg <- 0.5

  base_plt <-
    base_map_plot(map_obj$coast_topo,
      .bathy = NULL,
      c(exnt[1] - deg, exnt[2] + deg, exnt[3] - deg, exnt[4] + deg)
    )

  rm(deg)
}
```

## 4.2 Plot: Check Spatial Locations

Plot station lon/lat and check if location makes sense. If it does not, you may
need to update the document used to extract the metadata.

```{r map-data-names, fig.height=15, fig.width=15}
meta_format %>%
  nest(.by = name.of.water.body) %>%
  mutate(
    map_plt = map2(
      .x = name.of.water.body,
      .y = data,
      function(name, data) {
        base_plt +
          geom_point(
            data = data,
            aes(
              x = lon, y = lat,
              cruise = cruise,
              group = station
            ),
            color = "gray80",
            shape = 3
          ) +
          geom_text(
            aes(
              x = lon,
              y = lat,
              label = station
            ),
            data  = data,
            size  = 3,
            hjust = 0
          ) +
          theme_bw()
      }
    )
  ) %>%
  pull(map_plt)


(base_plt +
  geom_point(
    data = select(meta_format, -name.of.water.body),
    aes(
      x = lon,
      y = lat,
      cruise = cruise,
      group = station
    ),
    color = "gray80",
    shape = 3
  ) +
  geom_point(
    data = meta_format,
    aes(
      x = lon,
      y = lat,
      cruise = cruise,
      group = station,
      color = name.of.water.body
    ),
    show.legend = FALSE
  ) +
  geom_text(
    aes(
      x = lon,
      y = lat,
      label = station
    ),
    data = meta_format,
    # data  = filter(meta_format, str_detect(name.of.water.body, "Florida Keys")),
    size = 2,
    hjust = 0
  ) +
  facet_grid(~name.of.water.body) +
  theme_bw())
```

## 4.3 Plot: Interactive Map to Verify Stations

```{r check-spatial, fig.height=15, fig.width=20}
(meta_format %>%
   # filter(station == "2" | station == "MR") %>%
   # filter(station == "2") %>%
  ggplot(aes(x = lon, y = lat, 
             cruise = cruise,
              group = station
             )) +
  geom_point(data = select(meta_format, -name.of.water.body),
             color = "gray80",
             shape = 3) +
  geom_point(aes(color = name.of.water.body)) + 
  labs(
    x = NULL,
    y = NULL,
    color = NULL) +
   facet_grid(~name.of.water.body) +
   theme_bw()
  ) %>%
  plotly::ggplotly()  %>%
  plotly::layout(legend = list(orientation = "h", x = 0.2))
```

## 4.4 Check Samples are within 10 days of the Start of Cruise
```{r date-start-end, fig.width=20, fig.height=10}
new <- new.env()
source(here("scripts", "misc_functions.R"), local = new)
attach(new)
rm(new)

cruise_event <-
  meta_format %>%
  mutate(
    .keep = "used",
    start_date = str_extract(cruise, "\\d{4,5}"),
    start_date =
    if_else(
      is.na(start_date),
      as_date(str_c(year, month, day)),
      parse_date_time(start_date, orders = "yj"),
    ),
    
    end_date = start_date + 9
    
  ) %>%
  filter(
    .by = cruise, 
    start_date == min(start_date)) %>%
  distinct(cruise, start_date, end_date) %T>% print()


meta_format %>%
  mutate(
    date = glue("{year}-{month}-{day}"),
    date = as_datetime(date, tz = "UTC")
  ) %>%
  nest(.by = cruise) %>%
  mutate(
    plt = pmap(
      list(
        cruise,
        data
      ),
      plot_cruise_dates, # function to plot cruise date with length of cruise
      .cruise_event = .env$cruise_event
    )
  ) %>%
  pull(plt)
```

# 5.0 ---- Final Formatting before Saving ----

## 5.1 Final Format and Physical Sample Check

The file <hplc_progress_pres_abs.xlsx> is referenced to filter out samples that 
were not physically found in the freezer or had another reason for not to be
included in the SeaBASS extraction

```{r final-format}
# find previously saved files
prev_f <-
  # local_sv %>%                         # local
  here(cloud_dir, "blank_sheets") %>% # cloud

  dir_ls(regexp = glue("^[^~]*hplc.*\\.xlsx$"))

getSheetNames(prev_f)[-c(1, 5:12)]

hplc_check <-
  getSheetNames(prev_f)[-c(1, 5:12)] %>%
  map(., ~ read.xlsx(prev_f, sheet = .x, startRow = 2) %>%
  mutate(
    sheet = .x,
    collection_date = as.character(collection_date),
    station         = as.character(station),
    present         = as.character(present),
    absent          = as.character(absent),
    notes           = as.character(notes),
    collected_by    = as.character(collected_by)
  )) %>%
  list_rbind() %T>% print()

hplc_miss <- filter(hplc_check, str_detect(absent, "(?i)X"))
hplc_check <- filter(hplc_check, str_detect(present, "(?i)X")) %T>% print()

# filter out samples that are absent from the freezer
meta_format2 <-
  meta_format %>%
  inner_join(
    x  = .,
    y  = select(hplc_check, identifier, notes),
    by = join_by("sample" == "identifier")
  ) %>%
  # add letter if single, duplicate or triplicate
  mutate(
    .by = c(cruise, station, depth),
    indicate.if.filters.are.replicates = case_when(
      str_detect(cruise, "WS16") ~ "D",
      n() < 2 ~ "S",
      n() < 3 ~ "D",
      n() >= 3 ~ "T"
    ),
    notes = case_when(
      str_detect(sample, str_c("WS15264_", seq(41, 80), collapse = "|")) &
        row_number() >= 2 ~ "*optional processing duplicate,",
      str_detect(sample, str_c("WS15320_", c(seq(40, 74), 78, 80), collapse = "|")) &
        row_number() >= 2 ~ "*optional processing duplicate,",
    )
  ) %>%
  # expand ship name in cruise column
  mutate(
    cruise = case_when(
      str_detect(cruise, "WS") ~ str_replace(cruise, "WS", "Walton Smith "),
      str_detect(cruise, "WB") ~ str_replace(cruise, "WB", "Weather Bird II "),
      str_detect(cruise, "H") ~ str_replace(cruise, "H", "Hogarth "),
      str_detect(cruise, "(?i)CORE") ~ 
        str_replace(cruise, "CORE_", 
                    "CMS Collaborative Oceanographic Research and Education  ")
      
    )
  ) %T>% print()
```


## 5.2 Optional: Add Notes to Cruises that May not be There

```{r add-notes}
meta_format2 <-
  meta_format2 %>%
#   
#   mutate(
#     notes = case_when(
#       str_detect(sample) 
#       str_detect(cruise)
#     )
#   ) %>%
  
  # ---- previous notes from earlier cruises
# full_join(
  #   here("data", "raw", "hplc") %>%
  #     dir_ls(regexp = "09-02.*xlsx$") %>%
  #     str_subset("~", negate = TRUE) %>%
  #     read.xlsx(sheet = "SS from clients", startRow = 19) %>%
  #     filter(str_detect(sample, "WS16319")) %>%
  #     select("dup" = sample, cruise, station, depth),
  #   by = c("cruise", "station", "depth")
  # ) %>%
  # add note for samples in 2015/2016
  # mutate(
  #   notes = if_else(
  #     str_detect(sample, "WS16"),
  #     glue("**duplicate previously extracted in M-K 09-02 report, sample {dup},"),
  #     notes
  #   ),
  #   notes = if_else(year < 2017,
  #     glue(
  #       "{notes}",
  #       paste(
  #         "samples kept in -80C freezer until May 2023, then kept in liquid N2",
  #         "until shipment"
  #       ),
  #       .sep = " ",
  #       .na = ""
  #     ),
  #     glue("{notes}", .na = NULL)
  #   ),
  #   filter.storage.before.shipment.to.GFC =
  #     if_else(
  #       year < 2017,
  #       glue("{filter.storage.before.shipment.to.GFC}, and liquid N2 dry shipper"),
  #       filter.storage.before.shipment.to.GFC
  #     ),
  #   notes = as.character(notes)
  # ) %>%
  

  select(-contains("dup")) %T>% print()
```


## 5.3 Final Check for Missing Information and Summary of Samples
```{r check-na}
print(naniar::vis_miss(select(meta_format2, -1, -2)))
count(meta_format2, name = "total number of samples")
count(meta_format2, cruise, name = "total number per crusie")

count(meta_format2, cruise, indicate.if.filters.are.replicates, 
      name = "total", 
      .drop = FALSE) %>%
  filter(str_detect(indicate.if.filters.are.replicates, "D")) %>%
  mutate(total = as.integer(total/2))

count(meta_format2, station, 
      name = "total")
```

# 6.0 ---- Save Workbook ----

Save the metadata as an excel workbook locally and copy to the cloud if the 
results are satisfactory

```{r save-wb}
sv <- TRUE

dir_loc <- here("data", "metadata", "hplc_info")

if (TRUE) {
  wb <- loadWorkbook(template)

  writeData(
    wb,
    sheet    = 1,
    x        = grant_info$info,
    startRow = grant_info$grant_loc[1],
    startCol = grant_info$grant_loc[2] + 1,
    colNames = FALSE
  )

  writeData(
    wb,
    sheet    = 1,
    x        = meta_format2,
    startRow = grant_info$loc[1] + 1,
    colNames = FALSE
  )

  openXL(wb)
  if (sv) {
    cli::cli_alert_warning(
      c(
        "Make sure you want to save before continuing\n",
        "[Enter] to continue\n",
        "[Esc]   to cancel\n"
      )
    )
    readline("")
  
    
    dir_create(dir_loc)
    
    cli::cli_alert_info("Saving File!")
    cli::cli_alert_info("Location: {dir_loc}")
    # save
    saveWorkbook(
      wb = wb,
      file = here(
        dir_loc,
        glue(
          grant_info$last_nm,
          format(Sys.Date(), "_%Y%m%d_"),
          str_c(cruise_id[cruise_id %in% meta_format$cruise], collapse = "_"),
          ".xlsx"
        )
      ),
    overwrite = TRUE
    )
  }
}

# ---- run here to copy the newest xlsx file to the cloud service
if (FALSE) {
  dir_loc %>%
  dir_ls(regexp = grant_info$last_nm) %>%
  str_subset("~\\$", negate = TRUE) %>%
  last_mod() %>%
  file_copy(new_path = here(cloud_dir, "hplc", "hplc_sample_info"),
            overwrite = TRUE)
}
```



