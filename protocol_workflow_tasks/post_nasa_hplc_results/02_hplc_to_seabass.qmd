---
title: "HPLC SeaBass Submission"
author: "Sebastian Di Geronimo"
date: '2023-03-13'
format: html
---
# 1.0 ---- Documentation ----

## 1.1 Links: SeaBass Instructions for Submission of HPLC
Instructions: 
  <https://seabass.gsfc.nasa.gov/wiki/Data_Submission>
Check before submit: 
  <https://seabass.gsfc.nasa.gov/wiki/FCHECK#Download%20Source%20Code>

## 1.2 Header
Documentation:
<https://seabass.gsfc.nasa.gov/wiki/metadataheaders>

### 1.2.1 Required Fields:
investigators
affiliations
contact
experiment
cruise
station
data_file_name
documents
data_type
calibration_files
start_date
end_date
start_time
end_time
north_latitude
south_latitude
east_longitude
west_longitude
water_depth
missing
delimiter
fields
units

### 1.2.2 Conditionally Required Headers


### 1.2.3 HPLC Specific
<https://seabass.gsfc.nasa.gov/wiki/data_submission_special_requirements#Pigments,%20HPLC>
/HPLC_lab (e.g., NASA_GSFC)
/HPLC_lab_technician (e.g., Crystal_Thomas)

### 1.2.4 Ex Header
------------------------------------ start ------------------------------------
/begin_header	
/identifier_product_doi=10.5067/SeaBASS/EXPORTS/DATA001	
/received=20190807	
/affiliations=Bowdoin_College	
/investigators=Collin_Roesler	
/contact=croesler@bowdoin.edu	sdrapeau@bowdoin.edu
/experiment=EXPORTS	
/cruise=EXPORTSNP	
/data_file_name=EXPORTS_EXPORTSNP_HPLC-inline_survey_20180814.csv	
/original_file_name=EXPORTS_Roesler_08-06_report.xlsx	
/data_type=pigment	
/start_date=20180811	
/end_date=20180908	
/start_time=19:19:00[GMT]	
/end_time=19:44:00[GMT]	
/water_depth=na	
/measurement_depth=5.5	
/west_longitude=-145.960[DEG]	
/east_longitude=-131.543[DEG]	
/north_latitude=50.643[DEG]	
/south_latitude=49.4265[DEG]	
/documents=EXPORTS_Method_Inline_HPLC_Roesler_SeaBASS.docx	EXPORTS_2018_DATA_MASTER.xlsx
/calibration_files=EXPORTS_Method_Inline_HPLC_Roesler_SeaBASS.docx	
/data_status=final	
/missing=-9999	
/below_detection_limit=-8888	
/HPLC_lab=NASA_GSFC	
/HPLC_lab_technician=Crystal_Thomas	
/delimiter=comma	
/fields=hplc_gsfc_id	sample
/units=none	none
/end_header	

------------------------------------- end -------------------------------------

## 1.3 Data fields
1. Individual and summed pigments (based on SeaBASS fields/SeaHARRE reports)

2. Separate columns for any size-fractionated measurements (e.g., Tot_Chl_a_20umprefilt goes in a separate column from Tot_Chl_a)

3. Include "hplc_gsfc_id" as a column if your data were analyzed at the NASA GSFC lab to preserve the lab's sample ID

Report any replicate filters separately
Use the /below_detection_limit to mask any relevant values. It is distinct from the /missing value (e.g., /missing=-9999 vs. /below_detection_limit=-8888)
SeaBASS files may only contain data from a single cruise or deployment. If necessary, sort and separate your data by cruise then create multiple SeaBASS files
An online tool (HPLC2sb) is optionally available to help convert NASA GSFC HPLC spreadsheets into SeaBASS file format. However, please read its limitations and caveats carefully. <https://seabass.gsfc.nasa.gov/hplc2sb/>



# 2.0 ---- Setup ----


## 2.1 Load Libraries


```{r setup}
if (!nzchar(system.file(package = "librarian"))) 
  install.packages("librarian")

librarian::shelf(
  quiet = TRUE,
  librarian, conflicted, ggplot2, tibble, tidyr, readr, purrr, dplyr, stringr,
  forcats, lubridate, glue, fs, magrittr, here,
  # additional
  hms, janitor,
  cli
)

conflicts_prefer(
  dplyr::filter(), 
  dplyr::select()
  )
```

## 2.2 Load Data


```{r load-hplc}
# load consolidated HPLC by cruise
dir_ls(here("data", "processed", "hplc"),
       regexp = "RData") %>%
  sort(decreasing = TRUE)  %>%
  first() |>
  load() 

print(hplc_data)

# hplc_data <-
#   hplc_data %>%
#   filter(str_detect(cruise_id, "WS18285|WS21032"))

# location to save files
loc <- 
  here("data", "processed", "hplc", glue("ind_file_{Sys.Date()}"))
```

# 3.0

## 3.1

---- Edit Header Information Here -----------------------
```{r edit-chunk}
prepared_by <- 
  list(
    name  = "Sebastian Di Geronimo",
    email = "sebastian15@usf.edu"
  )
                    
contacts    <-
  tribble(
    ~invest,               ~email,             ~affil,
    "Frank Muller-Karger", "carib@usf.edu",    "University of South_Florida",
    "Daniel Otis",         "dotis@usf.edu",    "University of South_Florida",
    "Digna Rueda Roa",     "druedaro@usf.edu", "University of South_Florida"
) %>%
  mutate(
    across(
      everything(),
      (\(x) str_replace_all(x, "\\s", "_"))
    )
  )

acknowledge <-
  str_c("! ",
    c(
    "ACKNOWLEDGMENTS",
    "Observations were contributed by the South Florida Marine Biodiversity",
    "Observation Network (SFMBON) and the Southeast US Marine Biodiversity",
    "Observation Network (SEUSMBON). This research was funded by the National",
    "Oceanic and Atmospheric Administration (NOAA grant No. NA19NOS0120199);",
    "National Oceanic and Atmospheric Administration and Gulf of Mexico Coastal",
    "Ocean Observing System (NOAA-GCOOS Cooperative Agreement No. NA16NOS0120018);",
    "National Aeronautics and Space Administration (NASA grants No. NNX14AP62A,",
    "80NSSC20K0017, and 80NSSC22K1779)."
    ),
    collapse = "\n"
  ) %>%
  str_c(., "\n!")

hd_def <- list()

# version
hd_def$suffix <- "R1"

## version notes:
## if verion is R2 or above, add version notes if need to resubmit
## general application:
## add to all submissions or add specific info to cruise ids
  # glue("\n! <date of change> version RX")
if (!str_detect(hd_def$suffix, "R1")) {
  # add to the end of this
  hd_def$add_comment <-
    list(
      all = glue(
        "\n!",
        "\n! August 14, 2023 version R2 corrects volfilt ",
        "errors from mL to L",
      ),
      WS20278 = glue(
        "\n! August 14, 2023 version R2 pigment concentrations for sample ",
        "WS20278-32, original volume used was 190 mL, actual volume 1900 mL"
      )
    )
} else {
  hd_def$add_comment$all <- "!"
}

```

## 3.2 All SeaBass Standard Fields 

<https://seabass.gsfc.nasa.gov/wiki/stdfields>

```{r std-fields}
sb_field <- 
  read_tsv(here("data", "metadata", "seabass_standard_fields_all.txt"),
           show_col_types = FALSE,
           name_repair    = make_clean_names) %>%
  mutate(
    .after   = 1,
    low_name = str_to_lower(field_name),
    low_name = str_replace_all(low_name, "-", "_")
         )

# extract all field names from data and map to SeaBass standard names
hplc_data <- hplc_data2 <- 
  hplc_data %>% 
  mutate(
    # edit old names from previous report to match current SeaBass
    sb_name = map(
      .x = names,
      (\(x) 
            x  %>%
            mutate(
              low_name = str_replace(param_name, "(?i)t_caro", "tcar"),
              low_name = str_replace(low_name, "t_pg|t_pig", "tpg"),
              low_name = case_when(
                str_detect(low_name, "chl_c12") ~ "chl_c1c2",
                str_detect(low_name, "ppc_tpig") ~ "ppc_tpg",
                str_detect(low_name, "t_chl_a_tpg") ~ "tchla_tpg",
                str_detect(low_name, "tchl_a") ~ str_replace(low_name, 
                                                             "tchl_a", "tchla"),
                str_detect(low_name, "^t_chl") ~ str_replace(low_name, 
                                                             "t_chl", "tchl"),
                str_detect(low_name, "t_acc") ~ str_replace(low_name, 
                                                            "t_acc", "tacc"),
                .default = low_name)
              ) %>%
              left_join(.env$sb_field, by = c("low_name")))
      ),
    
    # calc duplicate info ----
    data_reps = map2(
      data,
      sb_name,
      function(x, y) {
        # add sd and bincount
        x <-
          x %>%
          group_by(station, depth, .drop = FALSE) %>%
          mutate(
            .keep = "used",
            across(
              tot_chl_a:last_col(),
              \(x) if_else(x < 0, NA, x)
            ),
            across(tot_chl_a:last_col(),
              .fns = list(
                sd = ~ sd(., na.rm = TRUE),
                bincount = ~ n()
              ),
              .names = "{.col}_{.fn}"
            )
          ) %>%
          select(-(contains("tot")[1]:(contains("chl_a_sd") - 1)[1])) %>%
          select(-where(~ all(. == 1 | . == -9999, na.rm = TRUE))) %>%
          ungroup() %>%
          select(-depth, -station)
  
        # create replicate and bincount field names 
        if (ncol(x) > 2) {
          rep_names <-
            tibble(param_name = names(x)) %>%
            filter(str_detect(param_name, "_sd|_bincount")) %>%
            separate_wider_regex(
              cols = param_name,
              patterns = c(
                "rep_name" = ".*",
                "seps" = "_.*"
              )
            ) %>%
            
            left_join(y, ., by = join_by("param_name" == "rep_name")) %>%
           unite("field_name",
             field_name, seps,
             sep = "",
             na.rm = TRUE,
             remove = FALSE
           ) %>%
             unite("param_name",
              param_name, seps,
              sep = "",
              na.rm = TRUE
            ) %>%
            mutate(
              units = if_else(
                str_detect(param_name, "bincount"), "none", units),
              )
          
        } else {
          rep_names <- NULL
          x <- NULL
        }

        return(
          list(
            reps = x,
            rep_names = rep_names
          )
        )
      }
    )
  ) %>%
  unnest_wider(data_reps) %>%
  mutate(
    data = map2(data, 
               reps,
               (\(x, y) bind_cols(x, y))
               ),
    sb_name = map2(sb_name, 
               rep_names,
               (\(x, y) bind_rows(x, y))
               )
  ) 

```


## 3.3 Calculate Replicate Info

With duplicate samples, there needs to be added <field>_sd and <field>_bincount

If no duplicate, set <field>_sd = -9999

NOTE: this is done in the above chunk


```{r calc-rep}
# hplc_data <- 
#   hplc_data %>%
#   mutate(
#     data_reps = map2(
#       data,
#       sb_name,
#       function(x, y) {
#         # add sd and bincount
#         x <-
#           x %>%
#           group_by(station, depth, .drop = FALSE) %>%
#           mutate(
#             .keep = "used",
#             across(
#               tot_chl_a:last_col(),
#               \(x) if_else(x < 0, NA, x)
#             ),
#             across(tot_chl_a:last_col(),
#               .fns = list(
#                 sd = ~ sd(., na.rm = TRUE),
#                 bincount = ~ n()
#               ),
#               .names = "{.col}_{.fn}"
#             ),
#             # across(
#             #   tot_chl_a_sd:last_col(),
#             #   \(x) if_else(is.na(x), -9999, x)
#             # )
#           ) %>%
#           select(-(contains("tot")[1]:(contains("chl_a_sd") - 1)[1])) %>%
#           select(-where(~ all(. == 1 | . == -9999, na.rm = TRUE))) %>%
#           ungroup() %>%
#           select(-depth, -station)
#   
#         # create field names 
#         if (ncol(x) > 2) {
#           rep_names <-
#             tibble(rep_name = names(x)) %>%
#             filter(str_detect(rep_name, "_sd|_bincount")) %>%
#             separate_wider_regex(
#               cols = rep_name,
#               patterns = c(
#                 "param_name" = ".*",
#                 "seps" = "_.*"
#               )
#             ) %>%
#             left_join(y, by = join_by("param_name")) %>%
#             select(-description) %>%
#             unite("field_name",
#               field_name, seps,
#               sep = "",
#               na.rm = TRUE
#             ) %>%
#             mutate(units = if_else(
#               str_detect(field_name, "bincount"), "none", units
#             ))
#         } else {
#           rep_names <- NULL
#           x <- NULL
#         }
# 
#         return(
#           list(
#             reps = x,
#             rep_names = rep_names
#           )
#         )
#       }
#     )
#   ) %>%
#   unnest_wider(data_reps) %>%
#   mutate(
#     data = map2(data, 
#                reps,
#                (\(x, y) bind_cols(x, y))
#                ),
#     sb_name = map2(sb_name, 
#                rep_names,
#                (\(x, y) bind_rows(x, y))
#                )
#   ) 

```

## 3.4 Header Information


TODO: change how list is created? 
  I don't know which one is easier to read and/or faster to run
  instead of: 
    hd_def <- list()
    hd_def$x <- <info>
    hd_def$y <- <more info>
    
  replace with:
    hd_def <- list(
        x = <info>,
        y = <more info>
        )


```{r default-info}
hd_def$invest   <- str_c(contacts$invest, collapse = ",")
hd_def$contact  <- str_c(contacts$email, collapse = ",")
hd_def$affil    <- str_c(contacts$affil, collapse = ",")
hd_def$expri    <- "SFMBON"
hd_def$expri_old <-
  glue(
    "SFP,",
    "Sanctuaries_Marine_Biodiversity_Observation_Network_(MBON)"
  )
hd_def$hplc_lab    <- "NASA_GSFC"	
hd_def$lab_tech    <- "Crystal_Thomas"	
hd_def$lab_instr   <- "Agilent"	
hd_def$lab_instr_m <- "RR1200"	

hd_def$type     <- "pigment"
hd_def$status   <- "final" # final - not intending to revisit
hd_def$wtr_dpth <- hd_def$stn <- "na"


hd_def$fields_extr <- 
  tibble(
    field_extr = c("hplc_gsfc_id", "sample", "date","time", "station",
                   "lon","lat","depth", "water_depth","volfilt")) %>%
  left_join(sb_field, by = c("field_extr" = "field_name"))

# TODO: fill in
# needs: checklist, cruises report?
hd_def$docs     <- "__TODO__"

# add comments to each file
hplc_data <-
  hplc_data %>%
  mutate(
    comments = map_chr(
      cruise_id,
      (\(.x) {
        if (!str_detect(hd_def$suffix, "R1$") &&
          .x %in% names(hd_def$add_comment)) {
          comms <- str_c(
            hd_def$add_comment$all,
            hd_def$add_comment[[.x]],
            sep = "\n"
          )
        } else {
          comms <- hd_def$add_comment$all
        }
        glue(
          .sep = "\n",
          .na = "!",
          "!",
          "! COMMENTS",
          "! Prepared by: {prepared_by$name}",
          "! Email: {prepared_by$email}",
          "! Creation Date: {format(Sys.Date(), \"%B %d, %Y\")}",
          # hd_def$add_comment,
          comms,
          # "!",
          "! Samples were processed at NASA GSFC by Crystal Thomas",
          "!",
          "! Values of -9999 represent missing information;",
          "!",
          "! Values of -8888 represent measurements below detection limits (LOD),",
          "! this represents pigments not detected or pigments present with",
          "! concentrations less than 0.0005 mg/m^3."
        )
      })
    ),
    precise_comm = map_chr(
      precision,
      (\(xl)
      if (any(str_detect(as.matrix(xl), "replicate"), na.rm = TRUE)) {
        glue("!")
      } else if (nrow(xl) > 1) {
        glue(
          "!",
          "\n! Coefficient of variation (CV) per report (replicate filter ",
          "precision)",
          "\n! TChl a = {str_c(xl$t_chl_a, collapse = \",\")};",
          "\n! Ppig   = {str_c(xl$ppig, collapse = \",\")}",
          "\n! Note: This cruise may not have replicate filters, but CV is",
          "\n! included beacuse the full report contains cruises with",
          "\n! replicate filters.",
          "\n!"
        )
      } else {
        glue(
          "!",
          "\n! Coefficient of variation (CV) per report (replicate filter ",
          "precision)",
          "\n! TChl a = {xl$t_chl_a};",
          "\n! Ppig   = {xl$ppig}",
          "\n! Note: This cruise may not have replicate filters, but CV is",
          "\n! included beacuse the full report contains cruises with",
          "\n! replicate filters.",
          "\n!"
        )
      })
    ),
    cal_file = map_chr(data, \(x) x$cal_files[[1]])
  )

rm(contacts, sb_field, prepared_by)
```



```{r header-skeleton}
header_skeleton <-
  glue::glue(
    "/begin_header",
    # required  
    "/investigators={hd_def$invest}",
    "/affiliations={hd_def$affil}",
    "!/affiliations=University of South Florida, MBON, SFMBON, SE US MBON",
    "/contact={hd_def$contact}",
    "/experiment={hd_def$expri}", 
    "!/experiment={hd_def$expri_old}",
    "/cruise={cruise_id}",
    "/station={hd_def$stn}",
    "/data_file_name={file_name}", # current name of data file, self-reference
    # "/documents={hd_def$docs}",    # additional info about experiment and cruise
    "/documents={doc},{map_file}",    # additional info about experiment and cruise
    # "/documents={doc}",    # additional info about experiment and cruise
    "/data_type={hd_def$type}",
    "/calibration_files={cal_file}",
    "/start_date={start_date}",
    "/end_date={end_date}",
    "/start_time={start_time}[GMT]",
    "/end_time={end_time}[GMT]",
    "/north_latitude={north_latitude}[DEG]",
    "/south_latitude={south_latitude}[DEG]",
    "/east_longitude={east_longitude}[DEG]",
    "/west_longitude={west_longitude}[DEG]",
    "/water_depth={hd_def$wtr_dpth}",
    "/missing=-9999",
    "/delimiter=comma",
    
    # HPLC required
    "/HPLC_lab={hd_def$hplc_lab}",
    "/HPLC_lab_technician={hd_def$lab_tech}",
    "/instrument_manufacturer={hd_def$lab_instr}",
    "/instrument_model={hd_def$lab_instr_m}",
    "/below_detection_limit=-8888",
    
    # conditional 
    
    # optional recommended
    "/data_status={hd_def$status}",
    
    # optional
    "/original_file_name={fbase}", 
    
    "{comments}",
    "{pc_com}",
    "{acknowledge}",
    "/fields={fields}", # fields of data 
    "/units={pun}",  # units for each column 
    "/end_header", 
    .sep = "\n") |>
  
  expression()
```


```{r extract-header-info}
hplc_w_head <-
  hplc_data %>%
  mutate(
    header_info = map(
      .x = data,
      function(x) {
        x %>%
        mutate(datetime = date + time) %>% # create datetime 
          
        # get min and max of head per cruise header info
        summarise(across(.cols = c(datetime, lon, lat), 
                         # new way using lambda notation
                         .fns = list(min = (\(x) min(x, na.rm = TRUE)),
                                     max = (\(x) max(x, na.rm = TRUE))),
                         .names = "{.col}_{.fn}")) %>%
        
        mutate(
          # split datetime to date and time separately
          start_date = format(ymd(as_date(datetime_min)),"%Y%m%d"),
          end_date   = format(ymd(as_date(datetime_max)),"%Y%m%d"),
          start_time = as_hms(datetime_min),
          end_time   = as_hms(datetime_max),
          
          # rename bound box variable names
          north_latitude = round(lat_max, 3),
          south_latitude = round(lat_min, 3),
          east_longitude = round(lon_max, 3),
          west_longitude = round(lon_min, 3),
          .keep = "unused")
        }
      ),
    # edit doc when have more documents 
    doc = glue("{rtf_file}", .na = "na")
    )

hplc_w_head
```

```{r create-header-info}
# if want to see header output, set to true
verb <- FALSE
verb <- TRUE

# cruise data header_info cruise_id 
hplc_final <-
  hplc_w_head %>%
  
  mutate(
     heads = pmap(
      .progress = TRUE,
      .l = list(data, header_info, cruise_id, sb_name, comments, precise_comm, 
                cal_file, doc, map_file),
      verb = verb,
      
      function(y, x, cruise_id, sb_name, comments, pc_com, cal_file, doc,
               map_file, verb) {
        # remove spaces in original base name 
        fbase <- 
          str_replace_all(unique(y$base), " ", "_") %>%
          str_c(collapse = ",")
        
        
        # create file name based on cruise ID
        file_name <-
          glue("{hd_def$expri}", "{cruise_id}", 
               "{hd_def$type}", "{x$start_date}_{hd_def$suffix}.sb", 
               .sep = "_")
        
        # fields and units standards: 
        #   <https://seabass.gsfc.nasa.gov/wiki/stdfields>
        # SeaBass standard fields
        field_nm <- c(hd_def$fields_extr$field_extr, sb_name$field_name)
        fields   <- str_c(field_nm, collapse = ",")
        
        # units each field
        pun <- str_c(c(hd_def$fields_extr$units, sb_name$units), collapse = ",")
        
        # evaluate header
        header <- with(x, eval(header_skeleton)) 
        
        if (verb) {
          cat("\n-----\n", cruise_id, "\n\n")
          print(header)
          cat("\n-----\n\n")
        }

        # return values
        return(
          tibble(
            header    = header,
            file_name = file_name,
            fld_use   = list(field_nm = field_nm)))
        }
     ),
     
     # renames the final data columns to match the "standard" fields 
     cols = pmap(
      list(data, heads, sb_name),
      def = hd_def,
      function(.x, .y, .z, def) {
        select(.x, any_of(
          c(def$fields_extr$field_extr,
            .z$param_name))
          ) %>%
          purrr::set_names(.y$fld_use[[1]])
        }
      )
     )

rm(verb)
```

## Saving Files in SeaBass Format
```{r save-files}
dir_create(loc) # create dir for each day running

cli::cli_alert_info("File Save Location: {.path {loc}}")

# save files
hplc_final %$%
  pwalk(list(cols, heads),
  # pwalk(list(hplc_final$cols, hplc_final$heads),
      function(x, y) {
        # write header
        # this method doesn't include `CR` which gives a warning when running
        # fcheck
        f <- file(here(loc, y$file_name), 
                  open = "wb") 
        cat(y$header, "\n", 
            sep  = "",
            file = f)
        close(f)
        
        x %>%
          # convert all to characters
          mutate(
            date = format(date,"%Y%m%d"),
            across(everything(), \(x) as.character(x)), # convert to char
            across(everything(), \(x) case_when(
                    is.na(x) ~ "-9999", # chg NA to -9999
                    .default = x)),
            # make sure no spaces exists in data before saving
            across(everything(),\(x) str_replace_all(x, "\\s", "")) 
           ) %>%

          # filter out rows where no data exists
          filter(!if_all(date:last_col(), \(x) x == "-9999")) %>%

          # write data after header
          write_delim(.,
                      delim     = ",",
                      file      = here(loc, y$file_name),
                      append    = TRUE,
                      col_names = FALSE
                      )
        }
      )
```



## Get Date Range of Each Cruise
Was useful for an email.
```{r date-range}
arg_ls <- 
  list(
    dt_rng = FALSE,
    dt_sv  = FALSE
  )

if (arg_ls$dt_rng) {
  dt_rng <-
    sb_data %>%
    mutate(
      .keep = "none",
      cruise   = str_extract(sample, "\\w{2,3}\\d{4,5}"),
      date     = as_date(date),
    ) %>%
    summarise(
      .by = cruise,
      num = n(),
      # date_min = as_date(date_min, format = ""),
      date_max = max(date),
      date_min = min(date)
    ) %>%
    arrange(date_max) %>%
    mutate(
      .before = date_max,
      date_diff = date_max - date_min,
      date_min_cr = str_extract(cruise, "\\d+"),
      date_min_cr = as_date(date_min_cr, format = "%y%j"),
      date_min_cr = format(date_min_cr, "%b %d"),
      date_max = format(date_max, "%b %d %Y"),
      ) %>%
    unite(col = "date_range", date_min_cr, date_max, sep = " - ") %>%
    relocate(date_diff, .after = date_range) %>%
    rename("date_min_of_samples" = date_min)
  
  dt_rng
  
  if (arg_ls$dt_sv) {
    write_csv(
      dt_rng,
      file  = here("date_range.csv"),
      quote = "none")
    }
  } else {
    cli_alert_info(
      glue_col("Removing `{red arg_ls}` because ",
               "`{red arg_ls$dt_rng}` = `{red {arg_ls$dt_rng}}`"))
    rm(arg_ls)
  }
```


## Copy files to box
If you want to copy files from local to cloud directory, you may run this
chunk. 

By default, it will skip. 
```{r copy-to-box}
shelf(cli)
source(here(".Rprofile"))
# set arguments in a list
arg_ls <- 
  list(
    # select location to save data
    cloud_loc = here(cloud_dir, "hplc", "seabass_submit"),
    # cloud_loc = here("data", "test"), # for testing of experimental change
    
    # select if want to write data to cloud and overwrite cloud directory data 
    wrt_cld = FALSE, # write data to cloud
    # wrt_cld = TRUE, # write data to cloud
    ovrwrt  = FALSE # overwrite if data exists
    # ovrwrt  = TRUE # overwrite if data exists
  )

if (!arg_ls$wrt_cld) {
  cli_alert_info("Skipping all files!")
  cli_alert_warning(
    c("If you want to save files to {.file {cloud_dir}}, ",
      "\nSet {.var {col_red(\"arg_ls$wrt_cld\")}} = {.var {col_red(TRUE)}}",
      "(currently set to {.var {col_red(arg_ls$wrt_cld)}})"))
  } else {
    # ---- check the intentions if wanting to save files to cloud
    meaning <-
      if_else(arg_ls$ovrwrt,
             glue_col(" meaning you {red {underline will be}} overwriting the ",
                      "data in the cloud directory, but if using {blue box}, ",
                      "it will be {blue {bold version controlled}}."),
              glue_col(" meaning you {red {underline will not be}} " ,
                       "overwriting data in the cloud."))
    
    cli_text("\n\n")
    cli_alert_warning("You might be overwriting previsouly saved data.")
    cli_alert_warning(c("Currently, {col_red(\"arg_ls$ovrwrt\")} = ",
                        "{.var {col_red(arg_ls$ovrwrt)}}{meaning}"))
    cli_alert_warning(c("If this was a mistake, change " ,
                        "{col_red(\"arg_ls$ovrwrt\")} ",
                        "= {.var {col_red(!arg_ls$ovrwrt)}}."))
    cli_text("Hit {col_red(\"\\\"enter\\\"\")} to continue or 
             {col_red(\"\\\"esc\\\"\")} to escape and correct.")
    invisible(readline(""))
    
    # ---- pushing files to cloud directory
    reduce(
      .f = left_join, 
      by = join_by(cruise_id),
      list(
        # ---- extract path to calibration files
        select(hplc_data, cruise_id, cal_file) %>%
        mutate(
          cal_file = map_chr(.x = cal_file,
                             ~ here("data", "raw", "hplc") %>%
                               dir_ls(regexp = .x))
          ),
        
        # ---- extract path to SeaBass submission files
        here("data", "processed", "hplc") %>%
        dir_ls(regexp = "ind_file") %>%
        sort(decreasing = TRUE) %>%
        first() %>%
        dir_ls() %>%
        tibble(sb_file = .) %>%
        mutate(
          cruise_id = str_extract(sb_file, "((WS|WB|SV|HG|H)[0-9].*)(?=_p)")
          ),
        
        # ---- extract path to cruise checklist files
        here("data", "raw", "hplc", "checklist") %>%
          dir_ls() %>%
          tibble(chk_file = .) %>%
        mutate(
          cruise_id = str_extract(chk_file, "((WS|WB|SV)[0-9].*)(?=\\.)")
          ),
        
        # ---- extract path to map files
         here("data", "processed", "hplc") %>%
         dir_ls(regexp = "map") %>%
         sort(decreasing = TRUE) %>%
         first() %>%
         dir_ls() %>%
         tibble(map_file = .) %>%
         mutate(
           cruise_id = str_extract(map_file, "((WS|WB|SV|H|HG)[0-9].*)(?=_s)")
           )
        )
      ) %>%
    
      # ---- add cloud directory for each cruise
      mutate(cloud_dir = here(arg_ls$cloud_loc, cruise_id)) %>%
      
      nest(.by = c(cruise_id, cloud_dir)) %$%
      
      pwalk(list(cruise_id, data, cloud_dir),
            function(x, y, dir_loc) {
              cli_h1(x)
              cli_alert_info("Copy Location: {.file {dir_loc}}")
              y <- 
                pivot_longer(
                  data      = y,
                  cols      = everything(),  # columns to pivot long,
                  names_to  = "file_type", # desired name for category column
                  values_to = "file_path", # desired name for value column
                  )  %>%
                filter(!is.na(file_path)) 
              
            walk2(
              .x = y$file_path,
              .y = dir_loc,
              function(from, to) {
             dir_create(to)
             tryCatch({
               file_copy(from, to, overwrite = arg_ls$ovrwrt)
               cli_alert_success("Copying: {.file {basename(from)}}")
               }, error = function(e) {
                 cli_alert_danger(c("Skipping: {.file {basename(from)}} ",
                                    "{col_red(\"Already exists!\")}"))
               })
                })}
          )
    
    if (!arg_ls$ovrwrt) {
      cli_text("\n\n")
      cli_alert_warning(
        c("If you want to {col_red(\"overwrite\")} existing ",
          "files, \nSet {.var {col_red(\"arg_ls$ovrwrt\")}} = ", 
          "{.var {col_red(TRUE)}} ",
          "(currently set to {.var {col_red(arg_ls$ovrwrt)}})"
        ))
      }
  } 

rm(arg_ls)
```

## Save Consolidated Info and Select Variables
If want to save a consolidated HPLC data file with the selected variables as a 
`.csv` file.
```{r sv-consolidated}
arg_ls <- 
  list(
    run   = FALSE,
    # run   = TRUE,
    local = FALSE,
    # local = TRUE,
    cloud = FALSE
    # cloud = TRUE
  )

if (arg_ls$local | arg_ls$cloud | arg_ls$run) {
  hplc_filt <-
    hplc_data2 %>%
    mutate(
      data = map2(
        .x = data,
        .y = sb_name,
        function(x, y) {
          
          x <- select(x, !contains(c("file", "base", "cal_files")))
          
          new_names <- tibble(og_names = names(x))  %>%
          left_join(y, by = join_by(og_names == param_name)) %>%
          mutate(
            field_name = if_else(is.na(field_name), og_names, field_name)
          )
          
          new_names$field_name
        
          names(x) <- new_names$field_name
          return(x)
          }
        
        )
    ) %>%
    select(1:3) %>%
    unnest(data) 
  
  
  if (arg_ls$local) {
    # save to local
    cli_alert_info("Saving consolidated HPLC to local")
    write_csv(hplc_filt,
              here("data", "processed", "hplc",
                   glue("hplc_consolidate_select_vars_",
                        "{Sys.Date()}",
                        ".csv")))
    }
  
  # save to cloud
  if (arg_ls$cloud) {
    cli_alert_info("Saving consolidated HPLC to cloud")
    write_csv(hplc_filt,
              here(cloud_dir, "hplc",
                   glue("hplc_consolidate_select_vars_",
                        ".csv")))
    }
  }
rm(arg_ls)
```


example documents from collin roesler:
/documents=
checklist_hplc_EXPORTS-EXPORTSNA_SR1812.rtf,
EXPORTS_Roesler_08-06_report_rev2.xlsx,
EXPORTS_pump_log_data_work_up_Sally_Ride_August_2018_QMA_SUPOR_organics.xls,
EXPORTSNP_SR1812_Roesler_sample_log_V2.xlsx,
R2R_ELOG_SR1812_FINAL_EVENTLOG_20180913_022931.xlsx

example from enrique:
x  hdr = {'/begin_header';
  strcat('/received=',date_received);
  '/investigators=Frank_Muller-Karger,Enrique_Montes';
  '/affiliations=University_of_South_Florida,USA';
'/contact=emontesh@usf.edu';
'/experiment=MBON';
strcat('/cruise=',cruise);
strcat('/data_file_name=',cruise,'_',data_type);
strcat('/documents=',cruise_report);
'/calibration_files=HPLC_method_summary';
'/delimiter=space';
'/data_type=pigment';
'/data_status=final';
strcat('/start_date=',start_date);
strcat('/end_date=',end_date);
strcat('/start_time=',start_time,'[GMT]');
strcat('/end_time=',end_time,'[GMT]');
strcat('/north_latitude=',lat_n,'[DEG]');
strcat('/south_latitude=',lat_s,'[DEG]');
strcat('/west_longitude=',lon_w,'[DEG]');
strcat('/east_longitude=',lon_e,'[DEG]');
'/below_detection_limit=-8888';
'/missing=-8888';
'/water_depth=-999';
'/cloud_percent=-999';
'/wave_height=-999';
'/wind_speed=-999';
'/secchi_depth=-999';
'!';
'!RUN BY: Enrique Montes';
'!Samples were processed at NASA GSFC by Crystal Thomas';
'!Measurements below detection limit are assigned the value -9999; this represents pigments not detected';
'!as well as pigments present but with concentrations less than 0.0005?g/L.';
'!Coefficient of variation (replicate filter precision) for TChl a =	1.64%; Ppig =	3.74%';
'!!Sky: variable conditions';
'!Water: variable conditions.';
'/fields=date,station,lon,lat,depth,Tot_Chl_a,Tot_Chl_b,Tot_Chl_c,alpha-beta-Car,But-fuco,Hex-fuco,Allo,Diadino,Diato,Fuco,Perid,Zea,MV_Chl_a,DV_Chl_a,Chlide_a,MV_Chl_b,DV_Chl_b,Chl_c1c2,Chl_c3,Lut,Neo,Viola,Phytin_a,Phide_a,Pras,Gyro,TChl,PPC,PSC,PSP,Tcar,Tacc,Tpg,DP,Tacc_TChla,PSC_Tcar,PPC_Tcar,TChl_Tcar,PPC_Tpg,PSP_Tpg,TChla_Tpg';
'/units=yyyymmdd,none,degrees,degrees,m,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,mg/m^3,none,none,none,none,none,none,none';
'/end_header'};




```{r}
# temp <- 
#   here(cloud_dir, "hplc", "seabass_submit") %>%
#   dir_ls(type = "directory")
# 
# dir_copy(
#   temp,
#   here("data", "processed", "hplc", "submit", basename(temp))
# )
# 
# here("data", "processed", "hplc", "submit") %>%
#   dir_ls(regexp = "\\.sb$",
#          recurse = TRUE) %>%
#          file_delete()
# 
# here("data", "processed", "hplc", "submit")  %>%
#   dir_tree()

```

