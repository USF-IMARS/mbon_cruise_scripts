---
title: "Check SeaBASS Files Before Submission"
author: "Sebastian DiGeronimo"
date: "2022-08-25"
output: html_document
---

# 1.0 ---- Summary of Document ----

This doucment is ment to be used before submission of new/old data to the NASA
SeaBASS Archive. 

Two processes:
1. Read `.sb` file to check for accuracy
2. Run NASA's FCHECK protocol to verify it conforms to their SeaBASS file 
   structure (i.e. `.sb`)


The sections are broken down into two parts:
1. HPLC data
  - pigment data
  - load 
  - FCHECK
  
2. Particulate/phyto/non-algal absorption (i.e. $ a_p, a_{ph},~\text{and}~a_{nap} $) and
   CDOM absorption (i.e. $ a_{CDOM} $)
   - bio-optical data
   - load
   - FCHECK


## Notes on FCHECK:

- `FCHECK` uses `Perl` to run
  - Since the SeaBASS archive has been around for awhile, they use the 
    programming language `Perl` to run the `FCHECK` process
  - if it is not available in your syste, it will ask you to download `Perl`
  - if you do not have `FCHECK`, you will be prompted to download it as well



# 2.0 ---- Setup ----

## 2.1 Load Libraries ----
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if (!nzchar(system.file(package = "librarian"))) 
  install.packages("librarian")

librarian::shelf(
  quiet = TRUE,
  librarian, conflicted, ggplot2, tibble, tidyr, readr, purrr, dplyr, stringr,
  forcats, lubridate, glue, fs, magrittr, here,
  # broom # optional
  
  # additional
  cli
)

conflicts_prefer(
  dplyr::filter(), 
  dplyr::select()
  )

{
  source(here(".Rprofile"))
  # attach functions to environment
  fcheck_func <- new.env()
  # here::here("scripts", c("file.R")) |>
  here::here("scripts", c("check_data.R", "misc_functions.R")) |>
  purrr::walk(~ source(.x, local = fcheck_func))
  attach(fcheck_func)
  rm(fcheck_func)
  
  # functions available in `fcheck_func` environment
  cli::cli_alert_info(
    c(
      "These are custom functions avaiable for this project!\n",
      "Documentations is location in {.path {here(\"scripts\")}}")
      )
  cli::cat_bullet(paste0(ls("fcheck_func"), "()"))
}
```


# 3.0 ---- Data: HPLC ----

## 3.1 Read SeaBass **HPLC** Files and Check for Issues
All columns are read as characters to check for any issues with the data
```{r read-seabass-hplc}
# get most recent directory created for seabass files
ind_f_dir <- 
  here("data", "processed", "hplc") %>%
  dir_ls(type   = "directory", 
         regexp = "ind_file") %>%
  sort(decreasing = TRUE)

# read seabass hplc files
sb_data <-
  ind_f_dir  %>%
  last_mod() %>%
  dir_ls(regexp = "\\.sb") %>%
  tibble(file = .) %>%
  mutate(data = map(
    file, 
    # function to read seasbass hplc files and extract data
    \(x) read_sb_files(x, col_type = "c", sample_type = "hplc")
    )) %>%
  unnest(data)

message(glue("The dimensions are: {dim_desc(sb_data)}"))
slice_sample(sb_data, n = 10)

filter(sb_data, if_any(sample:volfilt, \(x) is.na(x) | str_detect(x, "-9999")))
```


## 3.2 FCHECK: HPLC Checking `.sb` Files Locally for Issues

This is used by NASA to pre-check the .sb files before official submission 
process. This requires the use of "Perl" <https://www.perl.org/get.html>.
A quick download and it should work.

Then a download of FCHECK from NASA:
<https://seabass.gsfc.nasa.gov/wiki/FCHECK/fcheck4.tar>

Cruises not ready
- WS16074
- WS16130
- WS16263

SFMBON_WS16074_pigment_20160314_R1.sb: 1 error (1 unique) and 5 warnings (1 unique) were found.
SFMBON_WS16130_pigment_20160509_R1.sb: 1 error (1 unique) and 5 warnings (1 unique) were found.
SFMBON_WS16263_pigment_20160919_R1.sb: 1 error (1 unique) and 5 warnings (1 unique) were found.

```{r fcheck-hplc}
# ---- Toggle if want to see fcheck out put or look just for errors
verb <- FALSE
# verb <- TRUE

fcheck_results <- 
 ind_f_dir %>%
 last_mod() %>%
 dir_ls() %>%
 tibble(files = .) %>%
 sb_fcheck(
   .,
   col_name   = "files",
   loc_fcheck = here(), 
   verb       = verb)

# rm(verb, i, ind_f_dir)
```


# 4.0 ---- Data: ap, aCDOM, chl ----

ap    = Particulate absorption, phytoplankton absorption, and non-algal absorption
aCDOM = CDOM absorption 
chl   = [Chlorophyll-a]

## 4.1 Paths to Bio-optical Data


```{r directory-seabass-filt-cdom-chl}
cruise_dir <- 
  # here(cloud_dir, "seabass", "testing") %>%
  here(cloud_dir, "seabass", "temp") %>%
  dir_ls(type = "directory") %T>% print()

cruise_submit <- 
  here(cloud_dir, "seabass", "submitted") %>%
  dir_ls() %T>% print()

# list of files for submission
cruise_dir <- 
  str_subset(
    cruise_dir, 
    str_c(basename(cruise_submit), collapse = "|"),
    negate = TRUE
  ) %T>% print()

# check files to submit
cruise_dir %>%
  tibble(files = .) %>%
  mutate(
    base      = basename(files),
    year      = str_extract(base, "\\d{2}"),
    year      = glue("20{year}"),
    doy       = str_extract(base, "\\d{3}$"),
    doy       = as.numeric(doy),
    year      = as.numeric(year),
    count_ap  = map_int(files, ~ length(dir_ls(.x, regexp = "ap.*\\.sb$"))),
    count_ag  = map_int(files, ~ length(dir_ls(.x, regexp = "ag.*\\.sb$"))),
    count_chl = map_int(files, ~ length(dir_ls(.x, regexp = "chl.*\\.sb$"))),
  ) %>%
  arrange(year, doy) %>%
  select(
    "Year"                  = year,
    "Cruise ID"             = base,
    "ap Samples"            = count_ap,
    "ag Samples"            = count_ag,
    "Extracted chl Samples" = count_chl,
  ) # %>%
# write_csv(file = here("files.csv"))

# shell.exec(here())
 
# all seabass files 
cruise_dat <-
  cruise_dir %>%
  dir_ls(regexp = "\\.sb", recurse = 1) %>%
  tibble(file = .) %>%
  mutate(type = str_extract(file, "ag|ap|chl")) %T>% 
  print()

```


## 4.3 Read SeaBASS Files


```{r read-seabass-filt-cdom-chl}
# function to read metadata and data from .sb files
loads_datas <-
  . %>%
  mutate(
    info =
      map2(
        file,
        row_number(),
        # function to read seasbass hplc files and extract data
        \(x, y, z = nrow(.)) {
          cli_alert_info(glue("{y} of {z}: Reading {basename(x)}"))
          meta <-
            readr::read_lines(x) %>%
            str_subset("^/") %>%
            str_subset("=") %>%
            str_remove_all("/|\\[.*\\]") %>%
            str_split("=", simplify = TRUE) %>%
            as_tibble(.name_repair = ~ c("param", "value")) %>%
            pivot_wider(
              names_from   = c(param),
              values_from  = c(value),
              names_sep    = "_",
              names_repair = janitor::make_clean_names
            ) %>%
            mutate(
              across(
                everything(),
                ~ if_else(str_detect(.x, "na|no_cal_file"), NA, .x)
              ),
              water_depth = as.numeric(water_depth)
            )


          if (any(names(meta) %in% c("station", "station_name"))) {
            meta <-
              hablar::retype(meta, -station)
          } else {
            meta <- hablar::retype(meta)
          }

          data <- read_sb_files(x, col_types = "c", sample_type = "default")

          list(
            "meta" = meta,
            "data" = data
          )
        }
      )
  ) %>%
  unnest_wider(info) %T>% print()

# function to convert date and time to date_time
fix_time <- 
  . %>%
  mutate(
    .after     = end_time,
    start_date = ymd(start_date),
    end_date   = ymd(end_date),
    start_time = hms::as_hms(start_time),
    end_time   = hms::as_hms(end_time),
    date_time  = ymd_hms(paste(start_date, start_time))
  ) %>%
  arrange(date_time) 


# # cruise_dat <-
#   cruise_dat %>%
#   mutate(
#     data = map2(
#       file,
#       row_number(),
#       # function to read seasbass hplc files and extract data
#       \(x, y, z = nrow(cruise_dat)) {
#         cli_alert_info(glue("{y} of {z}: Reading {basename(x)}"))
#         read_sb_files(x, col_types = "c", sample_type = "default")
#       }
#     )
#   ) %>%
#   nest(.by = type) %>%
#   mutate(
#     data2 = map(
#       data,
#       \(x) unnest(x, cols = data)
#     )
#   ) %T>% print()



# ---- load seabass data
# --- ap
data_ap <-  
  cruise_dat %>%
  filter(type == "ap") %>%
  slice_head(
    prop = 1,
    # n = 20,
    by = type
    ) %>%
  loads_datas
  
# --- ag
load_ag <-
  cruise_dat %>%
  filter(str_detect(type, "ag")) %>%
  slice_head(
    prop = 1,
    # n = 20,
    by = type
    ) %>%
  loads_datas 

# --- chl
load_chl <- 
  cruise_dat %>%
  filter(str_detect(type, "chl")) %>%
  slice_head(
    prop = 1,
    # n = 20,
    by = type
    ) %>%
  loads_datas 




# ---- extract metadata
# --- ap
meta_ap <- 
  data_ap %>%
  select(-data) %>%
  # mutate(
  #   meta = map(meta,  
  #              ~ .x %>% 
  #             mutate(calibration_date = as.character(calibration_date)))
  #   ) %>%
  unnest(meta) %>%
  fix_time() %T>% print()

# --- ag
meta_ag <- 
  load_ag %>%
  select(-data) %>%
  unnest(meta) %>%
  fix_time() %T>% print()

# --- chl
meta_chl <- 
  load_chl %>%
  select(-data) %>%
  mutate(
    meta = map(
      meta, 
      ~ mutate(
        .x,
        calibration_date = as.character(calibration_date)
        )
      )
  ) %>%
  unnest(meta) %>%
  fix_time() %T>% print()

select(meta_ap, cruise, station, start_date, end_date)


calc_diff_time <- 
  . %>%
  summarise(
    .by = cruise,
    start_date = min(start_date),
    end_date = max(end_date),
    date_time_min = min(date_time),
    date_time_max = max(date_time)
  ) %>%
  mutate(
    date_diff = end_date - start_date,
    date_time_diff = date_time_max - date_time_min
    )
 

calc_diff_time(meta_ap) 
calc_diff_time(meta_ag) 
calc_diff_time(meta_chl) 
 
```


## 4.4 FCHECK: Bio-optical Checking `.sb` Files Locally for Issues

 Notes to fix 

chl 
- /calibration_data to /calibration_date
- extra comma: 
  - /units=yyyy,mo,dd,hh,mn,ss,degrees,degrees,none,none,m,,m,L,mg/m^3
  - /units=yyyy,mo,dd,hh,mn,ss,degrees,degrees,none,none,m,m,L,mg/m^3
- 1)  Required header label \"/water_depth\" not provided."
  - add /water_depth = na
  
  
```{r fcehck-seabass-filt-cdom-chl}
# # ---- Toggle if want to see fcheck out put or look just for errors
# verb <- FALSE
# # verb <- TRUE
# 
# 
# # fcheck_results3 <-
#   cruise_dir %>%
#     
#   # str_subset("", negate = FALSE) %>%
#   # str_subset("", negate = TRUE) %>%
#   map(
#     .,
#     \(x) {
#       dir_ls(x, regexp = "\\.sb") %>%
#         tibble(files = .) %>%
#         slice(1:10) %>%
#         sb_fcheck(
#           .,
#           col_name   = "files",
#           loc_fcheck = here(),
#           verb       = verb,
#           row_check  = "end"
#         )
#     },
#     .progress = TRUE
#   )
# 
#   cruise_dir %>%
#   dir_ls(., regexp = "\\.sb") %>%
#   tibble(files = .) %>%
#     mutate(cruise = str_extract(files, "\\w{1,3}\\d{4,5}")) %>%
#     slice(.by = cruise, 1:2) %>%
#     nest(.by = cruise) %>%
#     slice(1:2) %>%
#     mutate(
#       dats =
#     map(data,
#     ~ sb_fcheck(
#           .x,
#           col_name   = "files",
#           loc_fcheck = here(),
#           verb       = verb,
#           row_check  = "end"
#     ))
#   ) %T>% 
#   print()
```


```{r fcehck-seabass-filt-cdom-chl}
# ---- Toggle if want to see fcheck out put or look just for errors
verb <- FALSE
# verb <- TRUE

cruise_dir2 <- 
  cruise_dir %>%
  dir_ls(., regexp = "\\.sb") %>%
  tibble(files = .) %>%
  mutate(cruise = str_extract(files, "\\w{1,3}\\d{4,5}")) %>%
  nest(.by = cruise) %T>% 
  print()

# look for `furrr` and `progressr` package, and will skip is not downloaded.
parallel_pkgs <- c("furrr", "progressr", "future")
if (all(map_lgl(parallel_pkgs, ~ nzchar(system.file(package = .x))))) {
  librarian::shelf(parallel_pkgs)
  handlers("cli")

  tictoc::tic() # <-- start clock
  plan(multisession, workers = 5)

  with_progress({
    p <- progressor(steps = nrow(cruise_dir2))

    fcheck_results <-
      cruise_dir2 %>%
      mutate(
        dats =
          future_map2(
            data,
            cruise,
            p = p,
            \(.x, .y, p) {
              
              p(glue("Cruise ID: {.y} ({nrow(.x)} files)"))
              
              sb_fcheck(
              .x,
              col_name   = "files",
              loc_fcheck = here(),
              verb       = verb,
              row_check  = "end"
            ) 
              
              }
            # ~ sb_fcheck(
            #   .x,
            #   col_name   = "files",
            #   loc_fcheck = here(),
            #   verb       = verb,
            #   row_check  = "end"
            # )
          )
      )
  })

  plan(sequential)

  tictoc::toc() # <-- end clock

  unshelf(parallel_pkgs)
} else {
  cli_alert_warning(
    c(
      "The packages {.pkg {parallel_pkgs}} ",
      "{col_red(\"were not found\")} in your search path.\n\n",
      "If you want to do parallel processing, try:\n\n",
      "\t{.code librarian::shelf({parallel_pkgs[1]}, {parallel_pkgs[2]})}"
    )
  )
}

rm(parallel_pkgs)

```

## *WIP*: Show Results

This part may or may not work, depending on what data was loaded. 

Update to match the folder with the data loaded:
- `str_subset(".*<main folder name>*", negate = TRUE)`
- temp
- testing

```{r fcehck-seabass-filt-cdom-chl}
fcheck_results %>%
  unnest(dats) %$%
  list_c(fcheck2) %>%
  unique() %>%
  str_subset(".*temp*", negate = TRUE) %>% 
  str_remove("\\d\\)\\s+") %>%
  str_remove("^\\s+") %>%
  sort() %>% 
  cat(sep = "\n") 

# ---
fcheck_results3 %>%
  list_c() %$%
  list_c(fcheck2) %>%
  unique() %>%
  str_subset(".*testing.*", negate = TRUE) %>%
  sort() %>% 
  cat(sep = "\n") 


fcheck_results3 %>%
  list_c() %$%
  list_c(fcheck2) %>%
  tibble(tes = .) %>%
  slice(
    (19432 - 10):(19432 + 20), 
    (22095 - 10):(22095 + 20)
    )
  which(str_detect(tes, "mal"))
```


## X.0 ---- Move Files to Temporary Directory ----


```{r mv-files-to-temp}
{
  cli::cli_text(
    c(
      "Check that all SeaBASS files pass the {.emph FCHECK}
      {col_red(\"before\")} proceeding!"
    )
  )
  
  cont <- menu(c("Correct", "Incorrect"))
}

if (cont == 1) {

  cruise_dir %>%
  # str_subset("", negate = TRUE) %>%
  # str_subset("", negate = FALSE) %>%
  walk2(
    .,
    row_number(.),
    submit_path = here(cloud_dir, "seabass", "temp"),
    num = length(.),
    \(x, row, submit_path, num) {
      
      cli::cli_alert_info("Cruise: {basename(x)} ({row} of {num})")
      
      file_to_move <- dir_ls(x)
      
      cli_alert_info("Files amount: {length(file_to_move)}\n\n---\n\n")
      
      new_loc     <-  here(submit_path, basename(x))
      new_loc_sup <- here(new_loc, "supplimental_docs")

      # copy files to new location
      dir_copy(x, new_loc)

      # move non-seabass files (not .sb) to supplemental docs
      dir_create(new_loc_sup)

      dir_ls(new_loc, type = "file") %>%
      str_subset("\\.sb$", negate = TRUE) %>%
      file_move(new_loc_sup)

      }
    
  )

} else {
  cli_alert_warning("Skipping moving of SeaBASS directory.")
}



```


# X.0 ---- Load Bio-optical Data ----



```{r}
cruise_dir %>%
  dir_ls(regexp = "\\.sb", recurse = 1) %>%
  tibble(file = .) %>%
  mutate(type = str_extract(file, "ag|ap|chl")) %>%
  filter(str_detect(type, "ap") &
    str_detect(file, "_MR|_54|ap_WS_|ap_57_")) %>%
  # slice(1:10) %>%
  slice_head(prop = 0.1) %>%
  mutate(
    info =
      map(
        file,
        \(x) {
          meta <- readr::read_lines(x) %>%
            str_subset("^/") %>%
            str_subset("=") %>%
            str_remove_all("/|\\[.*\\]") %>%
            str_split("=", simplify = TRUE) %>%
            as_tibble() %>%
            rename("param" = 1, "value" = 2) %>%
            pivot_wider(
              data         = .,
              # id_cols      = c(file, type), # *optional* vector of unaffected columns,
              names_from   = c(param), # category column(s) to pivot wide
              values_from  = c(value), # value column(s) that hold data for each category column
              names_sep    = "_",
              names_repair = janitor::make_clean_names
            ) %>%
            hablar::retype(-station)


          data <- read_sb_files(x, col_types = "c", sample_type = "default")

          list(
            "meta" = meta,
            "data" = data
          )
        }
      )
  ) %>%
  unnest_wider(info) %>%
  unnest(meta) %>%
  unnest(data) %>%
  hablar::retype(-station) %>%
  mutate(
    start_date = ymd(start_date),
    end_date   = ymd(end_date),
    start_time = hms::as_hms(start_time),
    end_time   = hms::as_hms(end_time)
  ) %>%
  mutate(
    .by      = data_file_name,
    aph_norm = aph / max(aph, na.rm = TRUE)
  ) %T>% print() %>%
  # slice(1) %>%
  ggplot(aes(
    x = wavelength,
    # y = abs_ag,
    # y = aph,
    # color = month(start_date, label = TRUE, abbr = TRUE)
    color = station
  )) +
  geom_smooth(
    aes(y = ap),
    method = "loess",
    span = 0.01,
    formula = y ~ x,
    se = FALSE,
    linetype = "dashed"
  ) +
  geom_smooth(
    aes(y = aph),
    method = "loess",
    span = 0.01,
    formula = y ~ x,
    se = FALSE
  ) +
  # geom_line() +
  labs(color = "Month") +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(
    expand = c(0, 0),
    limits = c(0, NA),
    oob = scales::squish
  ) +
  # facet_wrap(~ year(start_date) + station, ncol = 3, scales = "free_y") +
  facet_wrap(~cruise, ncol = 4, scales = "free_y") +
  ggthemes::theme_calc()


```








# X.X ---- Base Map Data ----

Topography, ETOPO1, 0.0166667 degrees, Global (longitude -180 to 180), (Ice Sheet Surface) from https://coastwatch.pfeg.noaa.gov/erddap/griddap/

Global Self-consistent, Hierarchical, High-resolution Geography Database (GSHHG) from https://www.ngdc.noaa.gov/mgg/shorelines/

```{r base-map}
if (exists("base_plt")) {
  
  cli::cli_alert_info("{.var base_plot} is already loaded!")
  
} else {
  source(here("scripts", "map_files_dwnlod.R"))
  # path to base map files
  map_loc <- here("data", "map_shp")

  # spatial extent
  exnt <- 
    c(
      xmin = -84, # West
      xmax = -80, # East
      ymin = 24,  # South
      ymax = 28.5 # North 
      )
  ## ---- download topography (.nc) and coastline (.shp)
  world_download(
    path_land  = map_loc,
    path_topo  = map_loc,
    extent     = exnt,
    use_suffix = NULL
  )
  
  ## ---- Load Base Maps for Plotting
  # select and read coastline file from GSHHS then crop
  map_obj <-
    load_map_obj(
      .map_coast = map_loc,
      .map_state = NULL,
      .map_bath  = map_loc,
      .map_file  = "etopo1.nc",
      .extent    = exnt
    )

  ## ---- Plot Base Map
  base_plt <- base_map_plot(map_obj$coast_topo, .bathy = NULL, exnt)
  base_plt
}
```

```{r extract-data-lat-lon-info}
map_all <-
  . %>% 
  select(cruise, station, date_time, "lat" = north_latitude, "lon" = west_longitude) %>% 
  distinct() %>% 
  arrange(date_time) %>% 
  mutate(
    .by = cruise,
    lon_lag = dplyr::lead(lon),
    lat_lag = dplyr::lead(lat),
    ) %T>% print() %>% 
  nest(.by = cruise) %T>% print()

map_ap <- map_all(meta_ap) 
map_ag <- map_all(meta_ag) 
```

```{r plot-cruise-track, fig.width=15, fig.asp=1.2}
map_dat <-
  . %>%
  mutate(
    plt = map2(
      data,
      cruise,
      \(x, y) {
        base_plt +
          # ---- Sample Locations
          ggarchery::geom_arrowsegment(
            data = x,
            aes(
              x     = lon,
              xend  = lon_lag,
              y     = lat,
              yend  = lat_lag,
              # color = station
              color = fct_reorder(format(date_time, "%B %d"), date_time)
            ),
            arrow_positions = 0.5,
            arrows = arrow(length = unit(0.1, "inches")),
            na.rm  = TRUE
            # show.legend = FALSE
          ) +
          geom_point(
            data = x,
            aes(
              x = lon,
              y = lat
            ),
          ) +
          ggrepel::geom_text_repel(
            aes(
              x = lon,
              y = lat,
              label = station
            ),
            data = x,
            size = 2.5,
            hjust = 0,
            family = "serif"
          ) +
          labs(
            title = y,
            color = "Days of Coverage"
          ) +
          coord_sf(
            xlim = range(x$lon) + c(-0.5, 0.5),
            ylim = range(x$lat) + c(-0.5, 0.5)
            ) +
          theme(
            legend.position = c(0.2, 0.14),
            legend.text     = element_text(size = 10),
            legend.title    = element_text(size = 15)
          )
      }
    )
  )

# map_dat %$% 
#   plt

map_ap %>%
 # filter(str_detect(cruise, "WS15208")) %>%
  # slice(1) %>%
map_dat()  %$% 
  plt


map_ap %>%
 # filter(str_detect(cruise, "WS15208")) %>%
  # slice(1) %>%
map_dat()  %$% 
  plt
  
```

