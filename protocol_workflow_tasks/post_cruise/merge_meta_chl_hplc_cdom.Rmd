---
title: "Read All Meta for eDNA"
author: "Sebastian DiGeronimo"
date: "2022-09-13"
output: html_document
---

# TODO: format like merge_data.Rmd
# ---- 1.0 Load Libraries ----
```{r setup}
if (!nzchar(system.file(package = "librarian"))) 
  install.packages("librarian")

librarian::shelf(
  quiet = TRUE,
  librarian, conflicted, ggplot2, tibble, tidyr, readr, purrr, dplyr, stringr,
  forcats, lubridate, glue, fs, magrittr, here,
  
  # additional
  openxlsx
)

conflicts_prefer(
  dplyr::filter(), 
  dplyr::select()
  )

source(here("scripts", "misc_functions.R"))
if (!exists("cloud_dir")) source(here(".Rprofile"))

# `NA` values to skip when reading `.xlsx.
na_skip <- c("#N/A", "NA", "Skipped", "skipped", "na", "n/a", "n./a", "n.a", 
             "Flow", "*", stringi::stri_dup("-", 1:20))

# where to pull data from
# "cloud" - cloud path ~/<box-location>/mbon_imars_cruises/
# "local" - local path in this project, ~/data/metadata/
locat <- "cloud"

# check cloud - 1, local - 2, or both - 3
check <- 1
```

# ---- 2.0 Search files ----
## --- 2.1 Cloud Directory
After the first time, you will get a variable called `cloud_dir`. You should 
copy this into a `.Rprofile` so when you restart `R`, the path will be set.

i.e. copy "cloud_dir <- `<path-to-box>/mbon_imars_cruises`" 
*make sure to change `<path-to-box>` to the location on your computer.*
```{r find-files-box}
# folder path in cloud directory, 
# - If cancel, will be NULL
if (!exists("cloud_dir")) cloud_dir <- rstudioapi::selectDirectory()

if (!is.null(cloud_dir) & (check == 1 | check == 3)) {
  # searching cloud
  box_search <- 
   search_meta_folders(
      .dir_path   = here(cloud_dir, "years"),
      .folder_search = "metadata",
      return_type = "vector",
      recurse_level = 2) 
  
  files_all <- 
    dir_ls(
      path   = box_search,
      regexp = "\\.(xlsx)$"
    ) %>%
    # remove files to ignore or locked files (i.e. ~$)
    str_subset("~|ignore", negate = TRUE) %>% 
    tibble(file_path = .,
           base  = basename(.)) %>%
    
    # add columns for cruise ID and year
    mutate(
      cruise_id = str_extract(file_path, "\\w{1,2}\\d{4,5}"),
      cruise_id = if_else(str_detect(file_path, "(?i)core"), 
                          str_extract(file_path, "CORE_\\d{1,3}"),
                          cruise_id),
      cruise_id = str_replace(cruise_id, "WS24202", "WS24205"),
      year = str_extract(file_path, "[0-9]{4}"),
      year = as.numeric(year)
    )
  
  files_filt <- 
    files_all %>%
    # filter for cruise files
    filter(str_detect(file_path, "(?i)fknms_|core")) %T>% 
    print()
  
} else {
  message("Not looking for files in `cloud directory` because set as NULL.")
  box_search <- NULL
}
```

## --- 2.2 Local Directory
This is the location within this project that should be created when loading the
first time. 

If you do not want to use a cloud directory, you may use a local one.

If using both
```{r find-files-local}
if (is.null(box_search) | check == 2 | check == 3) {
  message("Searching local project for metadata!")
  files_local <-
    search_meta_folders(
      .dir_path   = here("data", "metadata"),
      # .folder_search = "fknms*",
      return_type = "vector",
      recurse_level = 4) %>%
    dir_ls(
      regexp  = "\\.(xlsx)$",
      recurse = TRUE
      )  %>%
    str_subset("~|ignore", negate = TRUE) %>% 
    tibble(
      file_path = .,
      base = basename(.)) %>%
  
    # ignore some files
    filter(str_detect(basename(file_path), "fknms_")) %T>% 
    print()
}
```

## --- 2.3 Compare Local and Cloud
Check the differences between the two to see if any discrepancies exists. 
You should only need to use the `cloud_dir` location


```{r compare}
# stopifnot(
#   "Will not be checking between cloud and local directories. Continue!" = 
#     exists("files_filt") & exists("files_local"))
# files_local[files_local$base %in% files_filt$base, 2]
# files_filt[!files_filt$base %in% files_local$base, 2]
# files_filt[files_filt$base %in% files_local$base, 2]
#   
#   anti_join(files_all, files_local,   by = "base") # all files in cloud, not in cloud
#   anti_join(files_local, files_filt,  by = "base") # files in local, not in cloud
#   anti_join(files_filt, files_local,  by = "base") # files in cloud, not in local
#   inner_join(files_filt, files_local, by = "base") # overlap between both
#   
#   # result is ones not in the local metadata files
#   full_join(files_filt, files_local,  by = "base") %>%
#     arrange(year, base) %>%
#     filter(is.na(file_path.y)) 
```

# ---- 3.0 Extract sheet name and row to read ----
Extracts sheet info by looking for prefix `field` or `Sheet1`
- if none are found, it will ask which of the sheets it could be

Extracts row info where data starts by looking for prefix `Sample`
- if none are found, it will ask which row it could be

Extracts how many columns to read in. This looks for either `notes` or 
`collector` as the last column.
```{r sheet-info}
files <- switch(
  locat,
  "cloud" = files_filt,
  "local" = files_local
)

# path to file with all inventory information
inventory <- 
  dir_ls(cloud_dir, regexp = "imars_inventory") %>%
  str_subset("~", negate = TRUE)

prev_cruise_id <- 
  inventory %>%
  openxlsx::read.xlsx(
    sheet = "cruise_summary"
  ) %>%
  pull(cruise_id)

files <- 
  files %>%
  filter(!cruise_id %in% prev_cruise_id)
  # filter(str_detect(cruise_id, "WS21093"))

files <- get_sheet_info(files)

files 

```

# ---- 4.0 Read all data as strings and merge ----
No filtering of data is done. It will remove all `NA`s that was specified above.
```{r all-data-as-str}
og_data_chr <-
  suppressMessages(
    files %>%
    mutate(
      data = pmap(
        list(file_path, sht_num, row, last_c),
        function(.x, .y, .z, .l) {
          temp <- openxlsx::read.xlsx(
            xlsxFile    = .x,
            sheet       = .y,
            cols        = 1:.l,
            startRow    = .z,
            na.strings  = na_skip,
            detectDates = FALSE
          ) %>%
            janitor::clean_names() %>%
            mutate(across(everything(), \(x) as.character(x))) %>%
            # remove column
            select(
              -any_of("time_filtered_24_00"), 
              any_of(c(cruise = contains("cruise")
                       # sample_collection_time_gmt = "sample_collection_time"
                       )
                     )
              ) %T>% 
          View(title = basename(.x))
        }
      )
    ) %>%
    unnest(data) %>%
    # combine different time column names into one
    unite(
      "sample_collection_time_gmt",
      contains(c(
        "sample_collection_time_gmt",
        "time_gmt",
        "time_sampled_24_00"
      )),
      sep    = "",
      na.rm  = TRUE,
      remove = TRUE
    ) %>%
    # convert to time by converting decimal (fraction of day in second) to HMS
    # convert decmial to seconds then convert to time
    # 24*60*60 = 86400 seconds in a day
    # i.e. 0.4826388888888889 = 41700 seconds
    # then hms::as_hms(41700) = 11:35:00
    type_convert() %>%
    mutate(
    #   date_time = date_mm_dd_yy + sample_collection_time_gmt,
    #   date_time = janitor::excel_numeric_to_date(
    #   date_time, 
    #   include_time = TRUE, 
    #   tz = "GMT"),
    # date_mm_dd_yy = as_date(date_time),
    # sample_collection_time_gmt = hms::as_hms(date_time)
      date_mm_dd_yy = janitor::excel_numeric_to_date(date_mm_dd_yy),
      sample_collection_time_gmt =
        hms::as_hms(sample_collection_time_gmt * 24 * 60 * 60)
    )
  ) %T>% print()
```

# ---- 5.0 Load data and correct formats if needed ----
Loads all data and fixes column formatting to merge afterwards.
This ignores potential NAs using any of 
- "NA", "Skipped", "skipped", "na", "n/a", "n./a", "n.a", "Flow", "*", or any 
  number of "-"s (i.e "-", "--", etc)
```{r load-data}
files <-
  files %>%
  # filter(cruise_id == "WS24139") %>%
  
  mutate(
    data = pmap(
      list(file_path, sht_num, row, last_c), 
      read_logsheets,
      na_skip = na_skip
      )
    ) 

files$data
```
## --- 5.1 Check Mismatched
Check which sheets and columns have different types from the rest so you can fix
using the above code. 

Currently, as of `Feb 1st, 2023`, there are no mismatches.
```{r mismatch}
mismatch <- t(janitor::compare_df_cols(files$data, return = "mismatch"))        
rownames(mismatch) <- c(NA, tools::file_path_sans_ext(files$base))
                         
mismatch

# # examine issue columns by entering the name of the file and the column that 
# # might be problematic
# # bad <- 
# (files %>%
#   filter(str_detect(file_path, "<enter-bad-base-file-name>")) %>%
#   pull(data))[[1]]  %$% 
#   unique(<variable-to-check>) 
# 
# # open file in excel if on windows?
# files %>%
#   filter(str_detect(file_path, "<enter-bad-base-file-name>")) %$% 
#   shell.exec(file_path)

# checks if any dates are betfore 2015. This would show bad dates and will need
# to be fixed
# An error means no bad dates
files %>%
  unnest(data) %>%
  filter(!is.na(vol_ml) & 
         date_mm_dd_yy <= as_date("2015-01-01")) 

rm(mismatch)
```

# ---- 6.0 Summarise Results ----
## --- 6.1 Unnest Metadata
```{r unnest-metadata}
meta_list <- list()

meta_list$sample_meta_data <-  
  files %>%
  unnest(data) %>% 
  select(-c(file_path:last_c), -contains("time_zone")) %>%
  
  filter(
     # removes rows that contain no data encoded as 
     # `1899-12-31 00:00:00` or `NA`
     # and vol_ml is `NA`
    !( (date_mm_dd_yy < as_date("2015-01-01") | is.na(date_mm_dd_yy))
      & is.na(vol_ml))
    
    # filter where sample_type (chl|hplc|cdom) has no vol and no date/time
    & !(is.na(date_time) & is.na(vol_ml))
    & !is.na(vol_ml)
    ) %>%
  mutate(
     .by = cruise_id,
     cruise_start = min(date_mm_dd_yy, na.rm = TRUE)
   ) %>%
  arrange(cruise_start) %>%
  select(-cruise_start) %>%
  group_by(cruise_id, station, depth_m) %>% # keep, theres a reason
  filter(

    !(
      !is.na(notes) 
      & str_detect(notes, "skipped b/c low on amber vials")
     ) 
    & if_any(
        vol_ml, 
        ~ !any(str_detect(sample_type, "(?i)chl|hplc") 
               & (is.na(.x) | .x == 0))
        ) 
    & !(!is.na(notes) 
        & str_detect(
          notes, 
          "Not taken|not enough water|no more cdom bottles|sample was not taken|sample was lost"))) %T>%
    print()
   

meta_list$sample_meta_data %$% unique(station)
```

## --- 6.2 Station Summary


After running, look for columns `chl_a`, `hplc` and `cdom` for *NA*s. 
- If you see one, check if the metadata is wrong

```{r station-summary}
meta_list$station_summary <- 
  meta_list$sample_meta_data %>%
  mutate(vol_ml = if_else(is.na(vol_ml) | vol_ml == 0, -9999, vol_ml)
  ) %>%
  select(-identifier, -sample_number, -notes, -c(1:base), -collector) %>%
  pivot_wider(
    data         = .,
    names_from   = c(sample_type), # category column(s) to pivot wide
    values_from  = c(vol_ml), # value column(s) that hold data for each category column
    names_sep    = "_",
    names_repair = janitor::make_clean_names,
    values_fn    = list(vol_ml = length)
    ) %>%
  ungroup() %T>%
  print()
```

## --- 6.3 Cruise Summary

Summarize number of each sample
- chl_a (i.e. a_ph)
- hplc
- cdom (i.e. a_CDOM)

```{r cruise-summary}
meta_list$cruise_summary <- 
  meta_list$station_summary %>% 
  summarise(
    .by  = cruise_id,
    date = min(date_mm_dd_yy, na.rm = TRUE),
    across(chl_a:cdom, sum, na.rm = TRUE)
    ) %>%
  mutate(
    date   = as_date(date),
    year   = year(date),
    month  = month(date),
    .after = date) %>%
  arrange(date) %T>% 
  print()
```

## --- 6.4 Sample Progress

```{r sample-progress}
meta_list$temp <- 
  meta_list$sample_meta_data %>%
  ungroup() %>%
  mutate(
    .keep = "none",
    cruise_id,
    station,
    identifier, 
    sample_type,
    present_missing   = NA,
    collection_date   = date_time, 
    collected_by      = collector,
    ) %>%
  nest(.by = sample_type) %>% 
  mutate(
    name_list = case_match(
      sample_type,
      "Chl-a" ~ "chl_progress",
      "HPLC"  ~ "hplc_progress",
      "CDOM"  ~ "cdom_progress" 
    )
  ) %>%
  pull(data, name = name_list) %T>% 
  print()
```

# ---- 7.0 Append Data to Inventory ----
```{r add-new-data}
meta_list <- list_flatten(meta_list, name_spec = "{inner}")

wb        <- loadWorkbook(inventory)

sheet_names <- 
  getSheetNames(inventory) %>% 
  str_subset("unknown", negate = TRUE) %T>%
  print()

for (i in sheet_names) {
  print(i)
  
  # ---- reorder data for sheet `sample_meta_data`
  meta_list[[i]] <- 
    select(
      meta_list[[i]],
      any_of(names(readWorkbook(wb, i)))
      )

  writeData(
    wb       = wb,
    sheet    = i,
    x        = meta_list[[i]],
    colNames = FALSE,
    startRow = nrow(readWorkbook(xlsxFile =  wb, sheet = i)) + 2
  )
}
openXL(wb)
```

## --- 7.1 Save to Local and Cloud
```{r save-local}
# choose to save or not
# sv <- FALSE
# sv <- TRUE
sv <- NULL

if (is.null(sv) & interactive()) {
  sv <- menu(c("Save", "DO NOT SAVE"))
  sv <- ifelse(sv == 1, TRUE, FALSE)
} else if (is.null(sv) & !interactive()) {
  sv <- FALSE
}

# save local
if (sv) {
    cli::cli_alert_warning(
      c(
        "Make sure you want to save before continuing\n",
        "[Enter] to continue\n",
        "[Esc]   to cancel\n"
      )
    )
    readline("")

    cli::cli_alert_info("Saving File!")
    cli::cli_alert_info("Location: {.path 
                        {here(\"data\", \"metadata\", \"inventory\")}}")
    cli::cli_alert_info("File Base Name: {.var imars_inventory}")
    dir_create(here("data", "metadata", "inventory"))
    # save
    saveWorkbook(
      wb = wb,
      file = here(
        "data", "metadata", "inventory",
        glue(
         "imars_inventory",
          format(Sys.Date(), "_%Y%m%d"),
          ".xlsx"
        )
      ),
      overwrite = TRUE
    )
}

here("data", "metadata", "inventory") %>%
  dir_ls(regexp = "imars_inventory") %>%
  str_subset("~\\$", negate = TRUE) %>% 
  last_mod() %>% 
  shell.exec()

# save to cloud
if (FALSE) {
  here("data", "metadata", "inventory") %>%
  dir_ls(regexp = "imars_inventory") %>%
  str_subset("~\\$", negate = TRUE) %>% 
  last_mod() %>%

  file_copy(new_path = inventory,
            overwrite = TRUE)
}
```

# ---- DELETE ----
```{r delete}
# wb <-
#   inventory %>%
#   openxlsx::getSheetNames() %>%
#   tibble(sheets = .) %>%
#   mutate(
#   data = map(
#     .x = sheets,
#     inventory,
#     .f = function(x, inventory) {
#       dat <- 
#         openxlsx::read.xlsx(xlsxFile = inventory, sheet = x) %>%
#         mutate(
#           try(across(contains("date"),
#                  ~ janitor::excel_numeric_to_date(.x,
#                                                   include_time = TRUE,
#                                                   round_seconds = TRUE)))
#         ) %T>% 
#         print()
#         
#       if (any(str_detect(names(dat), "sample_number"))) {
#         dat <-
#           mutate(dat,
#                  sample_number = as.character(sample_number))
#       }
#         # janitor::excel_numeric_to_date(date) %T>% print()
#         return(dat)
#     }
#   )
# ) 
# 
# date 
# collection_date = 42236.482639
# date_mm_dd_yy 
# date_time
# 
# test <-
# 
# # wb$data[[1]]
# wb %>%
#   mutate(
#     data2 = pmap(
#       list(data,
#            list("cruise_summary"   = cruise_summary, 
#      "chl_progress"     = sample_progress$data[[1]],
#      "hplc_progress"    = sample_progress$data[[2]],
#      "cdom_progress"    = sample_progress$data[[3]],
#      "station_summary"  = mutate(data_summary,
#        sample_collection_time_gmt = as.character(sample_collection_time_gmt)),
#      "sample_meta_data" = mutate(data_unnest,
#                                  sample_collection_time_gmt = as.character(sample_collection_time_gmt))
#      )
#      ),
#      \(x, y) bind_rows(x, y)
#     )
#   ) %>%
#   select(data2)

```



```{r save-inventory}
# list("cruise_summary"   = cruise_summary, 
#      "chl_progress"     = sample_progress$data[[1]],
#      "hplc_progress"    = sample_progress$data[[2]],
#      "cdom_progress"    = sample_progress$data[[3]],
#      "station_summary"  = data_summary,
#      "sample_meta_data" = data_unnest
#      ) 
# test  %>%
#   pull(data2) %>%
# openxlsx::write.xlsx(., 
#                      file = here("test_inventory.xlsx"),
#                      overwrite = FALSE, 
#                      append = TRUE)
# 
# shell.exec(here("imars_inventory_chl_hplc_cdom.xlsx"))
```



```{r label}
# # chl_2019 <- 
#    data_unnest %>%
#       # group_by(cruise_id, station, depth_m) %>%
#     select(-identifier, -sample_number, -notes, -c(1:base), -collector) %>%
# 
#     pivot_wider(
#     data         = .,
#     # id_cols      = c(), # *optional* vector of unaffected columns,
#     names_from   = c(sample_type), # category column(s) to pivot wide
#     values_from  = c(vol_ml), # value column(s) that hold data for each category column
#     names_sep    = "_",
#     names_repair = janitor::make_clean_names
#     ) %>%
#       View()
#     
# 
# 
# map2(.x = data_unnest$data,
#      .y = data_unnest$year, 
#      .f = ~ View(.x, title = .y))
# map2(.x = files$data,
#      .y = files$cruise_id, 
#      .f = ~ View(.x, title = .y))
# map(data_unnest$data, ~ unique(.x$cruise_id)  %>%
#   print())
# 
# # 
# data_unnest %>%
# 
#   filter(!(is.na(vol_ml) & is.na(lat) & is.na(lon) & is.na(date_mm_dd_yy))) %>%
#   filter((is.na(vol_ml & is.na(date_mm_dd_yy)))) %>%
#   select(-c(1:base)) %>%
#   pivot_wider(
#     data         = .,
#     # id_cols      = c(), # *optional* vector of unaffected columns,
#     names_from   = c(sample_type), # category column(s) to pivot wide
#     values_from  = c(vol_ml), # value column(s) that hold data for each category column
#     names_sep    = "_",
#     names_repair = janitor::make_clean_names
#     )
#   
  # count() %>%
  # ungroup() %>%
  # pivot_wider(
  #   data         = .,
  #   # id_cols      = c(), # *optional* vector of unaffected columns,
  #   names_from   = c(sample_type), # category column(s) to pivot wide
  #   values_from  = c(n), # value column(s) that hold data for each category column
  #   names_sep    = "_",
  #   names_repair = janitor::make_clean_names
  #   )
  # 
  # data_unnest  %>%
  # group_by(cruise_id, station, depth_m) %>%
    # select(-identifier, -sample_number, -notes, -c(1:base), -collector) %>%
 # pivot_wider(
 #    data         = .,
 #    # id_cols      = c(), # *optional* vector of unaffected columns,
 #    names_from   = c(sample_type), # category column(s) to pivot wide
 #    values_from  = c(vol_ml), # value column(s) that hold data for each category column
 #    names_sep    = "_",
 #    names_repair = janitor::make_clean_names,
 #    values_fn    = list(vol_ml = length)
 #    ) %>%
    # select(-c(millipore_e_dna:last_col())) %>%
    # filter(
    #   # if_any(chl_a:cdom, is.na) &
    #   !(if_all(chl_a:cdom, is.na) & 
    #     if_any(c(date_mm_dd_yy, sample_collection_time_gmt), is.na))
    #   ) %>%
    # ungroup() %>%
    #     janitor::get_dupes(cruise_id, station)
    # 
# data_unnest

```



```{r log-section}
# source(here("scripts/log_file_changes.R"))
# startup()
# current_log()
# log4r_info(verbose = FALSE)
# 
# read.delim("../data_change_logfile.txt")
```

