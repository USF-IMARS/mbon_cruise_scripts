---
title: "Read All Meta for eDNA"
author: "Sebastian DiGeronimo"
date: '2022-09-13'
output: html_document
---

# ---- Load Libraries ----
```{r setup}
if (!nzchar(system.file(package = "librarian"))) 
  install.packages("librarian")

librarian::shelf(
  librarian, conflicted, ggplot2, tibble, tidyr, readr, purrr, dplyr, stringr,
  forcats, lubridate, glue, fs, magrittr, here,
  # broom # optional
  
  # additional
  readxl, hms
)

# shelf(conflicted) # may be needed if won't allow loading of certain packages

conflicts_prefer(
  dplyr::filter(), 
  dplyr::select()
  )

# `NA` values to skip when reading `.xlsx.
na_skip <- c("NA", "Skipped", "skipped", "na", "n/a", "n./a", "n.a", "Flow", 
             "*", stringi::stri_dup("-", 1:20))

source(here("scripts", "misc_functions.R"))
source(here(".Rprofile"))
```

# ---- Search Box for FKNMS Logsheets ----
```{r find-files-box}
# folder path in cloud directory, 
# - If cancel, will be NULL
if (!exists("cloud_dir")) cloud_dir <- rstudioapi::selectDirectory()

if (!is.null(cloud_dir)) {
  # message(glue("Searching `{cloud_dir}` for metadata!"))
  box_search <- 
   search_meta_folders(
      .dir_path   = here(cloud_dir, "years"),
      .folder_search = "metadata",
      return_type = "vector",
      recurse_level = 2) 
  
  files_all <- 
    dir_ls(
      path   = box_search,
      regexp = "\\.(xlsx)$"
    ) %>%
    # remove files to ignore or locked files (i.e. ~$)
    str_subset("~|ignore", negate = TRUE) %>% 
    tibble(file_path = .,
           base  = basename(.))  %>%
    
    # add columns for cruise ID and year
    mutate(
      cruise_id = str_extract(file_path, "\\w{1,2}\\d{4,5}"),
      
      year = str_extract(file_path, "[0-9]{4}"),
      year = as.numeric(year)
    )
  
  files_filt <- 
    files_all %>%
    # filter for cruise files
    filter(str_detect(file_path, "(?i)fknms_")) %T>% 
    print()
  
} else {
  message("Not looking for files in `cloud directory` because set as NULL.")
  box_search <- NULL
}

# filter files after 2017, and not 2019 because this is when I started
files_filt <-
  files_filt %>%
  filter(
         year > 2017 &
         year != 2019
  #       ) %>%
  # filter(
  #   str_detect(cruise_id, "WS23061|H23138")
  ) %T>% 
  print()
```
# ---- Read Sheet Info ----
```{r read-meta-info}
files <- files_filt

files <- 
  get_sheet_info(
    files,
    sheet_type = "edna") %T>% 
  print()

```
# ---- Read Files ----
```{r}
# filter(files, str_detect(file_path, 'fknms_sample_logsheet_12_2021')) %>%
files %>%
  # slice(10) %>%
  filter(str_detect(file_path, "OCT")) %>%
  pull(file_path) %>%
  # openxlsx2::read_xlsx(sheet = "eDNA", detectDates = T,
  #                     # rows = 1:
  #                       )# %>%
 
  shell.exec()
```

```{r read-meta-sheets}
files <-
  files %>%
  # slice(10) %>%
  
  # filter(cruise_id == "H23138") %>%
  # filter(str_detect(file_path, 'OCT')) %>%
  
  mutate(
    data = pmap(
      list(file_path, sht_num, row, last_c, "edna", list(na_skip)), 
      read_logsheets
      ),
    data_row =  map_int(data, \(x) nrow(x))
    ) %>%
  filter(data_row > 0)
```
# ---- Check Mismatched Column Types or Names ----
This will show the column that have a different type than what it should be. The
issue arises when the column if of type "character" vs "numeric", "date", etc. 
The ones that are diferent from "logical" vs "numeric" are fine because 
"logical" can be converted to numeric as either a `1` or a `0`.
```{r mismatch}
mismatch <- t(janitor::compare_df_cols(files$data, return = "mismatch"))        
rownames(mismatch) <- c(NA, tools::file_path_sans_ext(files$base))
                         
mismatch

# # examine issue columns by entering the name of the file and the column that 
# # might be problematic
# # bad <- 
# (files %>%
#   filter(str_detect(file_path, "<enter-bad-base-file-name>")) %>%
#   pull(data))[[1]]  %$% 
#   unique(<variable-to-check>) 
# 
# # open file in excel if on windows?
# files %>%
#   filter(str_detect(file_path, "<enter-bad-base-file-name>")) %$% 
#   shell.exec(file_path)
```
# ---- Unnest Metadata and Format ----
```{r unnest-meta}
data_all <-
  files %>%
  select(-c(file_path:base)) %>%
  unnest(data) %>%
  filter(!if_all(mm_dd_yy:vol_ml, is.na) 
         & mm_dd_yy > as_date("2015-01-01")) %>%
  mutate(
    # time_gmt = round(time_gmt*86400),
    time_gmt = as_hms(time_gmt),
    year     = year(mm_dd_yy),
    month    = month(mm_dd_yy, label = TRUE),
    day      = day(mm_dd_yy),
    station  = str_to_upper(station),
    .before  = station
    ) %>%
  mutate(
    depth_m     = case_when(
      str_detect(sample, "(?i)blank") 
      | str_detect(station, "(?i)blank") ~ 0,
      is.na(depth_m) ~ 1,
      TRUE ~ depth_m),
    sample      = str_remove(sample, "\\*"),
    station     = str_replace(station, "(?i)blank.*", "blank"),
    replicate   = str_extract(sample, "(?i)[a-c]$|[1-6]$"), 
    replicate   = str_to_upper(replicate),
    filter_type = "sterivex",
    .after      = sample
  ) %T>% 
  print()
```



```{r unnest-meta}
data_summary <-
  data_all %>%
  filter(!(str_detect(station, "(?i)blan") |
    str_detect(sample, "(?i)blan"))) %>%
  mutate(vol_ml = if_else(is.na(vol_ml) | vol_ml == 0, -9999, vol_ml)) %>%
  select(-sample, -replicate, -sample_n, -notes, -collector) %>%
  pivot_wider(
    data         = .,
    names_from   = c(filter_type), # category column(s) to pivot wide
    values_from  = c(vol_ml), # value column(s) that hold data for each category column
    names_sep    = "_",
    names_repair = janitor::make_clean_names,
    values_fn    = list(vol_ml = length)
  )

dat_blnk <-
  filter(
    data_all,
    str_detect(station, "(?i)blan") |
      str_detect(sample, "(?i)blan")
  ) %>%
  mutate(vol_ml = if_else(is.na(vol_ml) | vol_ml == 0, -9999, vol_ml)) %>%
  select(-sample, -replicate, -sample_n, -notes, -collector) %>%
  pivot_wider(
    data         = .,
    names_from   = c(filter_type), # category column(s) to pivot wide
    values_from  = c(vol_ml), # value column(s) that hold data for each category column
    names_sep    = "_",
    names_repair = janitor::make_clean_names,
    values_fn    = list(vol_ml = length)
  ) %>%
  summarise(
    .by = cruise_id,
    date = min(mm_dd_yy, na.rm = TRUE),
    across(sterivex, sum, na.rm = TRUE)
  ) %>%
  rename("blank" = sterivex) %>%
  select(-date)

cruise_summary <-
  data_summary %>%
  summarise(
    .by  = cruise_id,
    date = min(mm_dd_yy, na.rm = TRUE),
    across(sterivex, sum, na.rm = TRUE)
  )

cruise_summary %>%
  left_join(dat_blnk) %>%
  mutate(
    date   = as_date(date),
    year   = year(date),
    month  = month(date),
    .after = date
  ) %>%
  arrange(date)

cruise_summary

# save current sheet
save_csv(
  .data          = data_all,
  save_location  = here("data", "metadata", "edna_meta"),
  save_name      = "edna_metadata",
  overwrite      = FALSE,
  verbose        = TRUE,
  time_stamp_fmt = "%Y-%m-%d"
)

save_csv(
  .data          = cruise_summary,
  save_location  = here("data", "metadata", "edna_meta"),
  save_name      = "edna_summary",
  overwrite      = FALSE,
  verbose        = TRUE,
  time_stamp_fmt = "%Y-%m-%d"
)
```

# ---- Merge to Enrique's Format ----
```{r convert-to-enrique}
master_file <-
suppressWarnings(master <- 
  here("data", "metadata") %>%
  dir_ls(., regex = "master_up-to-2022", recurse = 2) %>%
  read_xlsx(., 
            sheet = "eDNA2",
            .name_repair = "unique_quiet"))


{
  cat("\nData:\n")
  cat(names(data_all), sep = ", ")
  cat("\n\nMaster:\n")
  cat(names(master), sep = ", ")
}

finals <- 
  data_all %>%
  mutate(
    across(c(everything(), 
             -time_gmt, 
             -vol_ml), 
           as.character)) %>%
  select(-sample_n) %>%
  
  # rename to fit master
  rename(
    "Notes"       = "notes",
    "sample_id"   = "sample",
    "long"        = "lon",
    "lat"         = "lat",
    "depth"       = "depth_m",
    "Replicate"   = "replicate",
    "filter type" = "filter_type"
  ) 

finals <- 
  bind_rows(master, finals) %>%
  filter(cruise_id %in% pull(cruise_summary, cruise_id)) %>%
  select(-1)

if (FALSE) {
  arg <- list()
  arg$noaa_dir <- here("data", "metadata", "edna_meta", "send_noaa")
  dir_create(arg$noaa_dir)
  
  arg$dates <-
    pull(finals, mm_dd_yy) %>%
    as_date() %>%
    sort() %>%
    # range() %>%
    format("%b_%Y") %>%
    unique() %>%
    paste(collapse = "_") %>%
    str_to_lower()

  finals %>%
    xlsx::write.xlsx(.,
      here(
        arg$noaa_dir,
        glue(
          "eDNA_sample_master_",
          arg$dates,
          # sort(finals$mm_dd_yy,
          #   decreasing = TRUE
          # )[1] %>%
          #   as_date() %>%
          #   format("%b-%Y"),
          ".xlsx"
        )
      ),
      sheetName = "eDNA2",
      append = TRUE,
      # append = FALSE, # uncomment if want to overwrite
      showNA = FALSE,
      row.names = TRUE
    )
}
```
# ---- Added Dec 2022 and Jan 2023 Cruise ----
# KEEP for now!!!
```{r cruise-specific}
# meta <-
#   here(cloud_dir, "years", c("2022", "2023"))  %>%
#   fs::dir_ls(
#   recurse = TRUE,
#   regexp = "sample.*(12_2022|01_2023)"
# ) %>%
#   tibble(files = .) %>%
#   filter(!str_detect(files, "ignore")) %>%
#   mutate(
#     base = basename(files),
#     cruise_id = str_extract(files, "WS[0-9]{5}"),
#     info = map(files,
#                ~ read_xlsx(.x,
#                            .name_repair = janitor::make_clean_names,
#                            sheet = "eDNA",
#                            na = c(na_skip, ":"),
#                            # col_types = c("mm_dd_yy" = "date")
#                            # range = cell_cols(c(NA, "notes"))
#                            )  %>%
#                     select(-c(x:last_col())) %>%
#                     filter(!if_all(1:3, is.na) &
#                            !if_all(c(vol_ml, lat, lon), is.na)) #%>%
#                     # mutate(mm_dd_yy = janitor::excel_numeric_to_date(mm_dd_yy))
#                )
#   ) %>%
#   unnest(info)
# 
# 
# c("cruise_id", "station", "sample_id", "Extraction_no", "DNA_extr_kit", "mm_dd_yy", "year", "month", "day", "time_gmt", "lat", "long", "depth", "max_depth_m", "Replicate", "vol_ml", "filter type", "DNA_conc_ng_ul", "12s_sequ", "16S_sequ", "18S_sequ", "COI_sequ", "28S_sequ", "Date extracted", "Notes", "Manuscript", "collector")

# match_var <- c("station", "year", "month", "day", "Notes" = "notes", 
#                "long" = "lon", "lat" = "lat", "depth" = "depth_m", 
#                "Replicate" = "replicate", "filter type" = "filter_type")
# 
# names(meta)
# names(master)
#  finals <- 
#   meta %>%
#   select(-c(1:2)) %>%
#     rename("max_depth_m" = max_depth) %>%
#     
#      mutate(
#     depth_m = case_when(
#       str_detect(sample, "(?i)blank") | str_detect(station, "(?i)blank") ~ 0,
#       is.na(depth_m) ~ 1,
#       TRUE ~ depth_m),
#     sample = str_remove(sample, "\\*"),
#     replicate = str_sub(sample, -1L, -1L), 
#     replicate = if_else(str_detect(replicate, "(?i)[A-C1-6]"),
#                         replicate, NA_character_),
#     .after = sample
#   ) %>%
#   mutate( 
#     time_gmt = hms::as_hms(time_gmt),
#     year = year(mm_dd_yy),
#     month    = month(mm_dd_yy, label = TRUE),
#     day      = day(mm_dd_yy),
#     station  = str_to_upper(station),
#     .after = mm_dd_yy
#     ) %>%
#       
#   
#   mutate(
#     filter_type = "sterivex",
#     across(c(everything(), -time_gmt, -vol_ml), as.character)) %>%
#   select(-sample_n) %>%
#   full_join(master, ., by = match_var) %>%
#   # slice(1000:nrow(finals))
#   relocate(mm_dd_yy, .before = year) %>%
#   relocate(time_gmt, .after = day) %>%
#   relocate(cruise_id, .before = 1) %>%
#   relocate(sample_id = sample, .after = station) %>%
#   relocate(vol_ml, .after = Replicate) %>%
#   relocate(max_depth_m, .after = depth) %>%
#   filter(
#     (str_detect(year, "2022") & str_detect(month, "Dec") )|
#     (str_detect(year, "2023") & str_detect(month, "Jan")) 
#   ) 
# 
# if (FALSE) {
# finals %>%
#   xlsx::write.xlsx(.,
#     here("data", "metadata", "jan_dec.xlsx"), 
#     sheetName = "eDNA2", 
#     append = TRUE, showNA = FALSE
#   )
# }
```

# TO `REMOVE`
```{r delete}
# 
# recal <- tibble()
# 
# for (i in seq(nrow(files))) {
# # for (i in 1) {
#   # select sheet name with `field_logsheet`
#   cli::cli_alert_info("Getting sheet info for file: {.file {files$base[i]}}")
#   temp_sht <- excel_sheets(files$file_path[i]) 
#   sht_num  <- which(str_detect(temp_sht, "(?i)edna") & 
#                     !str_detect(temp_sht, "(?i)print"))
#   
#   if (identical(sht_num, integer(0))) {
#     cli::cli_alert_danger("Files doesn't have an eDNA sheet. Skipping file!")
#      recal <-
#       bind_rows(
#         recal,
#         tibble(file_path = files$file_path[i]))
#     next
#   }
#   
#   if (is_empty(sht_num)) {
#     sht_num <- menu(temp_sht, 
#                     title = glue(
#                       "\n-----\n\n",
#                       "Which sheet contains metadata?", 
#                       "\n(0 for none)"))
#   }
#   
#   # skip if no sheet name
#   if (sht_num == 0) {
#     recal <- 
#       bind_rows(
#         recal,
#         tibble(file_path = files$file_path[i]))
#     next
#   }
#   
#   # read sheet 
#   temp <- read_excel(
#     files$file_path[i],
#     sheet        = sht_num, 
#     n_max        = 5,
#     col_names    = FALSE,
#     .name_repair = "unique_quiet") 
#   
#   # row number that contains headers
#   row <- which(apply(temp, 1, function(x) any(grepl("(?i)MM:DD:YY", x))))
#   
#   if (is_empty(row) || is.na(row)) {
#     View(temp)
#     row <- readline("Which line is the header? ") %>%
#       as.numeric()
#   }
#   
#   # skip if no row info
#   if (is_empty(row) || is.na(row)) {
#     recal <-
#       bind_rows(recal, 
#                 tibble(file_path    = files$file_path[i], 
#                        sht_num = sht_num))
#     next
#   }
#   
#   # get last column to read
#   # either `notes` or `collector`
#   last_c <- which(grepl("(?i)notes|(?i)collector", temp[row,])) %>%
#     max()
#   
#   recal <- 
#     bind_rows(
#       recal,
#       tibble(
#         file_path = files$file_path[i],
#         sht_num = sht_num,
#         row     = row,
#         last_c  = last_c
#       )
#     )
# }
# 
# # joins recal and files
# files <- 
#   recal %>%
#   # drop row if no sheet exists in the file
#   drop_na(everything()) %>%
#   
#   # join with original info
#   left_join(files, by = "file_path")


# files <-
#   files %>%
#   mutate(
#     data = pmap(
#       list(file_path, sht_num, row, last_c), 
#       function(.x, .y, .z, .l) {
#         # load data
#         # select sheet, skip number of lines to sample 1, stop columns after
#         # `notes` or `collector`, remove NA values, clean names
#         temp <- read_xlsx(
#           path         = .x,
#           sheet        = .y,
#           skip         = .z - 1,
#           range        = cell_cols(c(NA, .l)),
#           .name_repair = janitor::make_clean_names,
#           na           = na_skip
#         ) %>%
#           mutate(
#             notes = as.character(notes)
#           ) 
#         
#         # filter out if sheet contained "did not take any"
#         if (isTRUE(any(str_detect(temp, "(?i)Did not take any")))) {
#           temp <- filter(temp, str_detect(notes, "(?i)did not"))
#         }
#         
#         return(temp)
#       }
#     )
#   )
```

