---
title: "Read All Meta for eDNA"
author: "Sebastian DiGeronimo"
date: '2022-09-13'
output: html_document
---

# ---- Load Libraries ----
```{r setup}
if (!nzchar(system.file(package = "librarian"))) 
  install.packages("librarian")

librarian::shelf(
  librarian, conflicted, ggplot2, tibble, tidyr, readr, purrr, dplyr, stringr,
  forcats, lubridate, glue, fs, magrittr, here,
  # broom # optional
  
  # additional
  readxl, hms
)

# shelf(conflicted) # may be needed if won't allow loading of certain packages

conflicts_prefer(
  dplyr::filter(), 
  dplyr::select()
  )

# `NA` values to skip when reading `.xlsx.
na_skip <- c("NA", "Skipped", "skipped", "na", "n/a", "n./a", "n.a", "Flow", 
             "*", stringi::stri_dup("-", 1:20))
```

# ---- Search Box for FKNMS Logsheets ----
```{r find-files-box}
# folder path in cloud directory, 
# - If cancel, will be NULL
if (!exists("cloud_dir")) cloud_dir <- rstudioapi::selectDirectory()

if (!is.null(cloud_dir) & (check == 1 | check == 3)) {
  # message(glue("Searching `{cloud_dir}` for metadata!"))
  box_search <- 
    # search_meta_folders(
    #   .dir_path   = here(cloud_dir, "years"),
    #   .folder_search = "metadata",
    #   return_type = "vector")
   search_meta_folders(
      .dir_path   = here(cloud_dir, "years"),
      .folder_search = "metadata",
      return_type = "vector",
      recurse_level = 2) 
  
  files_all <- 
    dir_ls(
      path   = box_search,
      regexp = "\\.(xlsx)$"
    ) %>%
    # remove files to ignore or locked files (i.e. ~$)
    str_subset("~|ignore", negate = TRUE) %>% 
    tibble(file_path = .,
           base  = basename(.)) 
  
  files_filt <- 
    files_all %>%
    # filter for cruise files
    filter(str_detect(file_path, "(?i)fknms_")) %>%
    
    # add columns for cruise ID and year
    mutate(
      cruise_id = str_extract(file_path, "\\w{1,2}\\d{4,5}"),
      
      year = str_extract(file_path, "[0-9]{4}"),
      year = as.numeric(year)
    ) %T>% print()
} else {
  message("Not looking for files in `cloud directory` because set as NULL.")
  box_search <- NULL
}
```

```{r search-fknms}
# folder paths in cloud directory
if (!file_exists(here("box_search.csv"))) {
  # if need box_search.csv 
  if (!exists("cloud_dir")) cloud_dir <- rstudioapi::selectDirectory()
  box_search <- 
  dir_ls(
    here(cloud_dir, "years"),
    regexp  = "metadata",
    type    = "directory",
    recurse = TRUE) %>%
    tibble(folder = .) %>%
    filter(!str_detect(folder, "train"))
} else {
  # read cloud directory search
  box_search <- read_csv(here("box_search.csv"), 
                         show_col_types = FALSE)
}

# find all file names with log in it
files_all <- 
  dir_ls(box_search$folder,
         regexp  = "^[^~]*\\.(xlsx)$",
         recurse = TRUE) %>%
  tibble(file_path = .,
         base      = basename(.)) %>%
    
  # extract path and file name, and year
  mutate(
    cruise_id = str_extract(file_path, 
                            "(FK|WS|WB|SV)[0-9]{4,5}"),
         year = str_extract(file_path, "[0-9]{4}"),
         year = as.numeric(year)
    )

# filter files after 2017, and not 2019 because this is when I started
# remove `ignore` file, and any without `fknms` in the name
files_filt <-
  files_all %>%
  filter(str_detect(basename(file_path), "fknms_") &
         year > 2017 &
         year != 2019 &
         !str_detect(file_path, "ignore|blank"))
```
# ---- Read Sheet Info ----
```{r read-meta-info}
files <- files_filt

recal <- tibble()

for (i in seq(nrow(files))) {
# for (i in 1) {
  # select sheet name with `field_logsheet`
  cli::cli_alert_info("Getting sheet info for file: {.file {files$base[i]}}")
  temp_sht <- excel_sheets(files$file_path[i]) 
  sht_num  <- which(str_detect(temp_sht, "(?i)edna") & 
                    !str_detect(temp_sht, "(?i)print"))
  
  if (identical(sht_num, integer(0))) {
    cli::cli_alert_danger("Files doesn't have an eDNA sheet. Skipping file!")
     recal <-
      bind_rows(
        recal,
        tibble(file_path = files$file_path[i]))
    next
  }
  
  if (is_empty(sht_num)) {
    sht_num <- menu(temp_sht, 
                    title = glue(
                      "\n-----\n\n",
                      "Which sheet contains metadata?", 
                      "\n(0 for none)"))
  }
  
  # skip if no sheet name
  if (sht_num == 0) {
    recal <- 
      bind_rows(
        recal,
        tibble(file_path = files$file_path[i]))
    next
  }
  
  # read sheet 
  temp <- read_excel(
    files$file_path[i],
    sheet        = sht_num, 
    n_max        = 5,
    col_names    = FALSE,
    .name_repair = "unique_quiet") 
  
  # row number that contains headers
  row <- which(apply(temp, 1, function(x) any(grepl("(?i)MM:DD:YY", x))))
  
  if (is_empty(row) || is.na(row)) {
    View(temp)
    row <- readline("Which line is the header? ") %>%
      as.numeric()
  }
  
  # skip if no row info
  if (is_empty(row) || is.na(row)) {
    recal <-
      bind_rows(recal, 
                tibble(file_path    = files$file_path[i], 
                       sht_num = sht_num))
    next
  }
  
  # get last column to read
  # either `notes` or `collector`
  last_c <- which(grepl("(?i)notes|(?i)collector", temp[row,])) %>%
    max()
  
  recal <- 
    bind_rows(
      recal,
      tibble(
        file_path = files$file_path[i],
        sht_num = sht_num,
        row     = row,
        last_c  = last_c
      )
    )
}

# joins recal and files
files <- 
  recal %>%
  # drop row if no sheet exists in the file
  drop_na(everything()) %>%
  
  # join with original info
  left_join(files, by = "file_path")
```
# ---- Read Files ----
```{r read-meta-sheets}
files <-
  files %>%
  mutate(
    data = pmap(
      list(file_path, sht_num, row, last_c), 
      function(.x, .y, .z, .l) {
        # load data
        # select sheet, skip number of lines to sample 1, stop columns after
        # `notes` or `collector`, remove NA values, clean names
        temp <- read_xlsx(
          path         = .x,
          sheet        = .y,
          skip         = .z - 1,
          range        = cell_cols(c(NA, .l)),
          .name_repair = janitor::make_clean_names,
          na           = na_skip
        ) %>%
          mutate(
            notes = as.character(notes)
          ) 
        
        # filter out if sheet contained "did not take any"
        if (isTRUE(any(str_detect(temp, "(?i)Did not take any")))) {
          temp <- filter(temp, str_detect(notes, "(?i)did not"))
        }
        
        return(temp)
      }
    )
  )
```
# ---- Check Mismatched Column Types or Names ----
This will show the column that have a different type than what it should be. The
issue arises when the column if of type "character" vs "numeric", "date", etc. 
The ones that are diferent from "logical" vs "numeric" are fine because 
"logical" can be converted to numeric as either a `1` or a `0`.
```{r mismatch}
mismatch <- t(janitor::compare_df_cols(files$data, return = "mismatch"))        
rownames(mismatch) <- c(NA, tools::file_path_sans_ext(files$base))
                         
mismatch

# # examine issue columns by entering the name of the file and the column that 
# # might be problematic
# # bad <- 
# (files %>%
#   filter(str_detect(file_path, "<enter-bad-base-file-name>")) %>%
#   pull(data))[[1]]  %$% 
#   unique(<variable-to-check>) 
# 
# # open file in excel if on windows?
# files %>%
#   filter(str_detect(file_path, "<enter-bad-base-file-name>")) %$% 
#   shell.exec(file_path)
```

# ---- Unnest Metadata and Format ----
```{r unnest-meta}
data_all <-
  files %>%
  select(-c(file_path:base)) %>%
  unnest(data) %>%
  filter(!if_all(mm_dd_yy:vol_ml, is.na) 
         & mm_dd_yy > as_date("2015-01-01")) %>%
  mutate(
    time_gmt = as_hms(time_gmt),
    year     = year(mm_dd_yy),
    month    = month(mm_dd_yy, label = TRUE),
    day      = day(mm_dd_yy),
    station  = str_to_upper(station),
    .before  = station
    ) %>%
  mutate(
    depth_m     = case_when(
      str_detect(sample, "(?i)blank") 
      | str_detect(station, "(?i)blank") ~ 0,
      is.na(depth_m) ~ 1,
      TRUE ~ depth_m),
    sample      = str_remove(sample, "\\*"),
    station      = str_replace(station, "(?i)blank.*", "blank"),
    replicate   = str_extract(sample, "(?i)[a-c]$|[1-6]$"), 
    replicate   = str_to_upper(replicate),
    filter_type = "sterivex",
    .after      = sample
  ) 
```



```{r unnest-meta}
data_summary <-
  data_all %>%
  filter(!(str_detect(station, "(?i)blan") |
         str_detect(sample, "(?i)blan"))) %>%
  mutate(vol_ml = if_else(is.na(vol_ml) | vol_ml == 0, -9999, vol_ml)
  ) %>%
  select(-sample, -replicate, -sample_n, -notes,  -collector) %>%
  pivot_wider(
    data         = .,
    names_from   = c(filter_type), # category column(s) to pivot wide
    values_from  = c(vol_ml), # value column(s) that hold data for each category column
    names_sep    = "_",
    names_repair = janitor::make_clean_names,
    values_fn    = list(vol_ml = length)
    )

dat_blnk <- 
  filter(data_all, 
         str_detect(station, "(?i)blan") |
         str_detect(sample, "(?i)blan")) %>%
  mutate(vol_ml = if_else(is.na(vol_ml) | vol_ml == 0, -9999, vol_ml)
  ) %>%
  select(-sample, -replicate, -sample_n, -notes,  -collector) %>%
  pivot_wider(
    data         = .,
    names_from   = c(filter_type), # category column(s) to pivot wide
    values_from  = c(vol_ml), # value column(s) that hold data for each category column
    names_sep    = "_",
    names_repair = janitor::make_clean_names,
    values_fn    = list(vol_ml = length)
    ) %>%
     summarise(
    .by  = cruise_id,
    date = min(mm_dd_yy, na.rm = TRUE),
    across(sterivex, sum, na.rm = TRUE)
    ) %>%
    rename("blank" = sterivex) %>%
  select(-date)

cruise_summary <- 
  data_summary %>% 
  summarise(
    .by  = cruise_id,
    date = min(mm_dd_yy, na.rm = TRUE),
    across(sterivex, sum, na.rm = TRUE)
    ) 

cruise_summary %>%
  left_join(dat_blnk) %>%
  mutate(
    date   = as_date(date),
    year   = year(date),
    month  = month(date),
    .after = date) %>%
  arrange(date) 

cruise_summary

# save current sheet
if (FALSE) {
  data_all %>%
  write_csv(
    here("data", "metadata", 
         glue("edna_metadata",
          # time of save, so you don't overwrite
          format(Sys.time(), '_%Y%m%d_%H%M%S'),
          ".csv")),
    na = ""
    )
  cruise_summary %>%
  write_csv(
    here("data", "metadata", 
         glue("edna_summary",
          # time of save, so you don't overwrite
          format(Sys.time(), '_%Y%m%d_%H%M%S'),
          ".csv")),
    na = ""
    )
}
```
```{r}
data_all %>%
  filter(cruise_id == "WS21212")
```


# ---- Merge to Enrique's Format ----
```{r convert-to-enrique}
master_file <-
suppressWarnings(master <- 
  here("data", "metadata") %>%
  dir_ls(., regex = "master_up-to-2022") %>%
  read_xlsx(., 
            sheet = "eDNA2",
            .name_repair = "unique_quiet"))


{
  cat("\nData:\n")
  cat(names(data_all), sep = ", ")
  cat("\n\nMaster:\n")
  cat(names(master), sep = ", ")
}

finals <- 
  data_all %>%
  mutate(
    across(c(everything(), 
             -time_gmt, 
             -vol_ml), 
           as.character)) %>%
  select(-sample_n) %>%
  
  # rename to fit master
  rename(
    "Notes"       = "notes",
    "sample_id"   = "sample",
    "long"        = "lon",
    "lat"         = "lat",
    "depth"       = "depth_m",
    "Replicate"   = "replicate",
    "filter type" = "filter_type"
  ) 

finals <- bind_rows(master, finals)

if (FALSE) {
  finals %>%
  xlsx::write.xlsx(.,
    here("data", "metadata", glue("master_up-to-",
                                  sort(finals$mm_dd_yy, 
                                       decreasing = TRUE)[1] %>%
                                    as_date() %>%
                                    format("%b-%Y"), 
                                  ".xlsx")), 
    sheetName = "eDNA2", 
    append    = TRUE, 
    showNA    = FALSE,
    row.names = TRUE
  )
}
```
# ---- Added Dec 2022 and Jan 2023 Cruise ----
# KEEP for now!!!
```{r cruise-specific}
# meta <-
#   here(cloud_dir, "years", c("2022", "2023"))  %>%
#   fs::dir_ls(
#   recurse = TRUE,
#   regexp = "sample.*(12_2022|01_2023)"
# ) %>%
#   tibble(files = .) %>%
#   filter(!str_detect(files, "ignore")) %>%
#   mutate(
#     base = basename(files),
#     cruise_id = str_extract(files, "WS[0-9]{5}"),
#     info = map(files,
#                ~ read_xlsx(.x,
#                            .name_repair = janitor::make_clean_names,
#                            sheet = "eDNA",
#                            na = c(na_skip, ":"),
#                            # col_types = c("mm_dd_yy" = "date")
#                            # range = cell_cols(c(NA, "notes"))
#                            )  %>%
#                     select(-c(x:last_col())) %>%
#                     filter(!if_all(1:3, is.na) &
#                            !if_all(c(vol_ml, lat, lon), is.na)) #%>%
#                     # mutate(mm_dd_yy = janitor::excel_numeric_to_date(mm_dd_yy))
#                )
#   ) %>%
#   unnest(info)
# 
# 
# c("cruise_id", "station", "sample_id", "Extraction_no", "DNA_extr_kit", "mm_dd_yy", "year", "month", "day", "time_gmt", "lat", "long", "depth", "max_depth_m", "Replicate", "vol_ml", "filter type", "DNA_conc_ng_ul", "12s_sequ", "16S_sequ", "18S_sequ", "COI_sequ", "28S_sequ", "Date extracted", "Notes", "Manuscript", "collector")

# match_var <- c("station", "year", "month", "day", "Notes" = "notes", 
#                "long" = "lon", "lat" = "lat", "depth" = "depth_m", 
#                "Replicate" = "replicate", "filter type" = "filter_type")
# 
# names(meta)
# names(master)
#  finals <- 
#   meta %>%
#   select(-c(1:2)) %>%
#     rename("max_depth_m" = max_depth) %>%
#     
#      mutate(
#     depth_m = case_when(
#       str_detect(sample, "(?i)blank") | str_detect(station, "(?i)blank") ~ 0,
#       is.na(depth_m) ~ 1,
#       TRUE ~ depth_m),
#     sample = str_remove(sample, "\\*"),
#     replicate = str_sub(sample, -1L, -1L), 
#     replicate = if_else(str_detect(replicate, "(?i)[A-C1-6]"),
#                         replicate, NA_character_),
#     .after = sample
#   ) %>%
#   mutate( 
#     time_gmt = hms::as_hms(time_gmt),
#     year = year(mm_dd_yy),
#     month    = month(mm_dd_yy, label = TRUE),
#     day      = day(mm_dd_yy),
#     station  = str_to_upper(station),
#     .after = mm_dd_yy
#     ) %>%
#       
#   
#   mutate(
#     filter_type = "sterivex",
#     across(c(everything(), -time_gmt, -vol_ml), as.character)) %>%
#   select(-sample_n) %>%
#   full_join(master, ., by = match_var) %>%
#   # slice(1000:nrow(finals))
#   relocate(mm_dd_yy, .before = year) %>%
#   relocate(time_gmt, .after = day) %>%
#   relocate(cruise_id, .before = 1) %>%
#   relocate(sample_id = sample, .after = station) %>%
#   relocate(vol_ml, .after = Replicate) %>%
#   relocate(max_depth_m, .after = depth) %>%
#   filter(
#     (str_detect(year, "2022") & str_detect(month, "Dec") )|
#     (str_detect(year, "2023") & str_detect(month, "Jan")) 
#   ) 
# 
# if (FALSE) {
# finals %>%
#   xlsx::write.xlsx(.,
#     here("data", "metadata", "jan_dec.xlsx"), 
#     sheetName = "eDNA2", 
#     append = TRUE, showNA = FALSE
#   )
# }
```

