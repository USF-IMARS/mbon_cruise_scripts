---
title: "CDOM Processing"
author: "Sebastian DiGeronimo"
date: '2022-07-06'
output: html_document
---


TODO: include something about ignoring bad samples
should be something like bad in the notes spreadsheet to filter it out
```{r setup, include=FALSE}
root <- rprojroot::find_rstudio_root_file()
knitr::opts_chunk$set(echo = TRUE)
library("ggplot2")
library("tibble")
library("tidyr")
library("readr")
library("purrr")
library("dplyr")
library("stringr")
library("forcats")
library("lubridate")
library("glue")
library("fs")
library("magrittr")
# library("broom") # optional
```

```{r create-dir}
# will create a set directory if does not exists
# useful for new projects
subDir <-
    c("data/raw",
      "data/processed",
      "data/plots",
      "data/metadata",
      "data/raw/cdom",
      "Rmd",
      "scripts")

fs::dir_create(path = paste0(root,"/",subDir))
rm(subDir)
```


```{r}
old_dir <- fs::dir_ls(paste0(root, "/old_idl/"))
for (i in 2:length(old_dir)) {
  cat("Folder:", old_dir[i])
  (cat("", gsub("\\.(txt|pro|jrn)$","", list.files(path = old_dir[i])), sep ="\n"))
  cat("\n")
}

cat(gsub("\\.m$","", list.files(path = old_dir[i])), sep ="\n")

```

# Files to change:
----
# Orig:
  Folder: D:/sample_processing/old_idl/orig_enrique_idl_routines_cdom
    1. sta_files.txt = 
    2. temp.jr       = renames and moves files into nested dir
    3. readsp.pro    =
    4. agdata.pro    =
    5. sta_plot.pro  =
    6. interpol2.pro =
    
    ag.txt        != A data
    abs_ag.txt    != abs data
-----
# New Instrument Jen:
  Folder: D:/sample_processing/old_idl/new_jen_idl_cdom
    1. sta_files_850.txt
    4. agdata_850.pro
    5. sta_plot_850.pro
----
# Updated:
  Folder: D:/sample_processing/old_idl/new_jen_idl_cdom_updated
    1. sta_files_850.txt
    4. agdata_850.pro
    5. sta_plot_850.pro


------
# Info
  1. sta_files.txt 
                  5/6 columns (depends on instrument)
                  staNum = sample ID without `WS`
                  file1 = scan 1 of run ID
                  file2 = scan 2 of run ID
                  file3 = scan 1 of run ID
                  blankf = blank run ID	
                  bias = wavelength for bias
                  color = color for graph
  2. temp.jrn      
                  renames files, then you copy them to nested folder
                  rename by lowercase month, remove leading 0s in file name, add 
                  `_` between month and number, removes `.SP` extension
  3. readsp.pro    
                  seems like just reading the files and formatting to remove 
                  beginning header
                  counts number of files in nested folder of data
                  for loop, replaces first 86 rows to '', then read files again
                  to contain 2 columns of wv and A
                  
  4. agdata.pro    
                  takes the 2 column data files and takes data column into large
                  dataframe of all columns with headers as file names
  5. sta_plot.pro 
                  read each row in sta_files and gives each column to a variable
                  create 3 matrices, rows of 601 and columns # of samples
                  for each column will add the data related to sta_files
                  
                  cols: staNum		file1		file2		blankf		bias	color
  
                  file1 cols goes to scan1
                  file2 cols goes to scan2 
                  blankf cols goes to blank
                  
                  create abs.txt file
                  formula: 
                          avg scan = mean(scan1+scan2) - blank
                          scan1&scan2&blank * 23.03
                          = L * log(10) <- L = 10cm
                          
                  smooth data: 
                          27 width moving boxcar
                          
                  Bias
                          bias col (mostly 10 nm window)
                          if 550: take average of 540nm to 560nm
                          if 600: take average of 590nm to 610nm
                          if 620: take average of 610nm to 630nm
                          if 670: take average of 660nm to 680nm
                          if 680: take average of 670nm to 690nm
                          if 690: take average of 680nm to 700nm
                          if 700: take average of 690nm to 710nm
                          if 710: take average of 705nm to 715nm - 5 nm window
                          if 720: take average of 715nm to 725nm - 5 nm window
                          if 750: take average of 745nm to 755nm - 5 nm window
                          if 800: take average of 780nm to 800nm
                          
                          then subtract bias from spectra
                          
                  Slope 
                        = -ag(375)/ag(412)
                        natural log (ag(375):ag(412))
                        least square polynomial fit of degree 1, take slope
                        = -ag(350)/ag(450)
                        natural log (ag(375):ag(412))
                        least square polynomial fit of degree 1, take slope
                        = -ag(350)/ag(500)
                        natural log (ag(375):ag(412))
                        least square polynomial fit of degree 1, take slope
                        = ag 400
                        # ignore? find where ag > 0.15 for all scans, count
                        # ignore? find where ag <= 0.05 for all scans, count
                        # ignore? = ag 375
                        
                        ag(400) * exp(S(350:500)*(wv-400))
                        
                  Plot
                        plot,lam,ag(0,*),$
                        xr=[400,800],xs=1,$
                        yr=[-0.05,0.4],ys=1,$
                        xtit='Wavelength (nm)',$
                        ytit='a!DCDOM!N(!4k!3) (m!E-1!N)',$
                        tit='WS19119 - MBON',thick=1.5
                        
                                                plot,lam,ag(0,*),$
                        xr=[300,800],xs=1,$
                        yr=[0.0001,20],ys=1,$
                        xtit='Wavelength (nm)',$
                        ytit='a!DCDOM!N(!4k!3) (m!E-1!N)',$
                        tit='WS19119 - MBON',thick=1.5
  6. interpol2.pro 
                  rotate final matrix and save a .txt 

```{r read-data}
date_run <- "22MAY10"

df_cdom <-
  fs::dir_ls(paste0(root, "/data/raw/cdom/", date_run, "/"),
             regexp = "\\.SP") %>%
  map_dfr(., ~ read_tsv(.x, skip = 86, col_names = F), .id = "file") %>%
  mutate(file = gsub("\\.SP$", "", basename(file))  %>%
           str_to_lower) %>%
  rename(lambda = 2, absorb = 3)

```
```{r metadata}
file_match <-
  fs::dir_ls(paste0(root, "/data/metadata/"), regexp = regex(str_to_lower("10MAY2022"))) %>%
  readxl::read_xlsx(skip = 6, .name_repair = janitor::make_clean_names) %>%
  select(sample_id, comments) %>%
  # mutate(scan1 = str_split(sample_id," \\+ ", simplify = T)[,1])
  separate(sample_id,
           c("scan1", "scan2"),
           sep = " \\+ ",
           remove = F) %>%
  mutate(
    scan2 = str_c(substr(scan1, 1 , 5), scan2),
    cruise_id = case_when(
      str_detect(comments, "Milli-q")  ~ "blank",
      TRUE ~ str_split(comments, " ", simplify = T)[, 1]
    )
  ) %>%
  pivot_longer(
    cols = c(scan1, scan2), names_to = "scans", values_to = "file"
  )
  

```

```{r}
# length of cuvette
L     <-  10
const <-  L * log(10)

scan_num <- file_match %$%
  n_distinct(scans)


df_cdom_mg <- left_join(df_cdom, file_match, by = "file") %>%
  relocate(sample_id:scans, .before = file) %>%
  group_by(sample_id, lambda) %>%
  mutate( 
    abs_mean    = mean(absorb),
    abs_log     = absorb * const,
    abs_log_avg = mean(abs_log)
    ) %>%
  filter(grepl("1", scans)) %>%
  ungroup


# df_splt <- df_cdom_mg %>%
#   group_split(cruise_id) %>%
#   set_names(value = unique(df_cdom_mg$cruise_id))

# blanks <- df_splt[[1]]
# df <- df_splt[-1] 

blanks <- 
  df_cdom_mg %>%
  filter(grepl("blank",cruise_id)) 
  
df <- df_cdom_mg %>%
  filter(!grepl("blank",cruise_id))

avg_blank <- blanks %>%
  group_by(lambda) %>%
  summarise(avg = mean(abs_mean),
            med = median(abs_mean),
            avg_log = mean(abs_log_avg),
            med_log = mean(abs_log_avg)) %>%
  arrange(-lambda)
```

# Plot Blank Scans
```{r}
(
  df_cdom_mg %>%
    group_by(file) %>%
    filter(grepl("blank", cruise_id)) %>%
    ggplot(aes(
      x = lambda, y = abs_mean, color = sample_id
    )) +
    geom_line(size = 0.3) +
    geom_line(
      data = avg_blank,
      aes(x = lambda, y = avg),
      color = "black",
      inherit.aes = F
    ) +
    geom_smooth(
      data = avg_blank,
      aes(x = lambda, y = med),
      color = "black", se = F, 
      inherit.aes = F
    ) +
    labs(
      title = "Blank Scans (10 cm Milli-q Water)",
      subtitle = paste("Number of Scans:", scan_num),
      x = "Wavelength (\u03BB)",
      y = expression(a[milli-q]~(lambda)~(m^-1)) ,
      color = NULL
    ) +
    scale_x_continuous(expand = c(0, 0)) +
    scale_y_continuous(labels = ~ format(.x, scientific = FALSE)) +
    coord_cartesian(ylim = c(-0.001, 0.001), xlim = c(199, 805)) +
    theme_bw() +
    theme(
      legend.position = c(0.8, 0.83),
      legend.text = element_text(size = 8),
      legend.key.size = unit(0.37, "cm"),
      legend.title = element_blank(),
      legend.margin = margin(
        t = 0,
        r = 0,
        b = 0,
        l = 0,
        unit = "pt"
      )
    )
) 
```


```{r}

df <-   df %>%
    group_by(sample_id) %>%
    mutate(
      abs_avg = abs_mean - avg_blank$avg,
      abs_med = abs_mean - avg_blank$med,
      log_avg = abs_log_avg - avg_blank$avg_log,
      log_med = abs_log_avg - avg_blank$med_log
    ) %>%
      ungroup

(
  df_abs %>%
    
    ggplot(aes(
      x = lambda, y = abs_avg, color = file
    )) +
    geom_line(show.legend = F) +
    scale_x_continuous(expand = c(0, 0)) +
    coord_cartesian(ylim = c(NA, 0.2), xlim = c(300, 700))
) %>%
  plotly::ggplotly()

```

```{r 375-412}

polys <- function(.x, .var) {
  values <- .x$.var
}

slopes <- df %>%
  group_by(file) %>%
  filter(lambda >= 375 & lambda <= 412)  %>%
  # select(file, lambda, log_avg) %>%
  group_map(~lm(log_avg ~ 1 + poly(lambda, 1), data = .x)) %>%
  map_df(broom::tidy) %>%
  filter(grepl("poly", term)) %>%
  select(estimate) %>%
  mutate(
    abs = df %>%
          filter(lambda == 400) %>%
          select(lambda, log_avg) 
  ) %>%
    unnest(abs)
 
tibble( 
  lambda = (seq(800,200, -1))
  ) %>%
    mutate(
      test = slopes$log_avg[3] * exp(slopes$estimate[3] * (lambda - 400))
    ) %>%
  ggplot(aes(x = lambda, y = test)) +
  geom_line() +
  scale_x_continuous(expand = c(0,0)) +
  scale_y_continuous(labels = ~ format(.x, scientific = FALSE)) +
  theme_bw() +
  coord_cartesian(
    xlim = c(300,800),
    ylim = c(-0.05,0.4)
    )

```



```{r}
zoo::rollmean(c(1.0, 1.0, 2.0, 3.0, 4.0, 1e18, 4.0, 3.0, 2.0, 1.0, 1.0), k = 3,
              align = "left")

(27-1)/2
600 - (27+1)/2

sta %>%
  as_tibble() %>%
  mutate(test = seq(800,200,-1))
```

