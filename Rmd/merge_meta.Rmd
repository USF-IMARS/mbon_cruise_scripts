---
title: "Read All Meta for eDNA"
author: "Sebastian DiGeronimo"
date: '2022-09-13'
output: html_document
---

# ---- Load Libraries ----
```{r setup}
librarian::shelf(
  librarian, ggplot2, tibble, tidyr, readr, purrr, dplyr, stringr,
  forcats, lubridate, glue, fs, magrittr, here,
  # broom # optional
  
  # additional
  readxl
)

library("conflicted")

conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")

# `NA` values to skip when reading `.xlsx.
na_skip <- c("NA", "Skipped", "skipped", "na", "n/a", "n./a", "n.a", "Flow", 
             "*", stringi::stri_dup("-", 1:20))

# where to pull data from
# "cloud" - cloud path ~/<box-location>/mbon_imars_cruises/
# "local" - local path in this project, ~/data/metadata/

```

# ---- Create Directories in Box with apad, cdom, and metadata ----
```{r}
# inventory <- ("C:/Users/spd19/OneDrive/Documents/College/IMaRS/HPLC Data and documentation/Inventory.xlsx") %>%
#   readxl::read_xlsx() %>%
#   select(cruise = `Cruise ID`) %>%
#   drop_na() %>%
#   mutate(
#   cruise = str_replace(cruise, " \\(279\\)", ""),
#   year = str_extract(cruise, "[0-9]{2}"),
#   year = str_c("20", year)
#   )
# 
# directs <- glue::glue("C:/Users/spd19/Box/mbon_imars_cruises/{inventory$year}/{inventory$cruise}/"
#            ) 
# 
# glue("{directs}CDOM") %>%
#              fs::dir_create()
# 
# glue("{directs}apad") %>%
#              fs::dir_create()
# 
# glue("{directs}CDOM") %>%
#              fs::dir_create()
# 
# "C:/Users/spd19/Desktop/"
```

# ---- Search Box for FKNMS Logsheets ----
```{r}
# folder paths in cloud directory
if (!file_exists(here("box_search.csv"))) {
  # if need box_search.csv 
  if (!exists("cloud_dir")) cloud_dir <- rstudioapi::selectDirectory()
  box_search <- 
  dir_ls(
    here(cloud_dir, "years"),
    regexp  = "metadata",
    type    = "directory",
    recurse = TRUE) %>%
    tibble(folder = .) %>%
    filter(!str_detect(folder, "train"))
} else {
  # select if alraedy exists
  box_search <- read_csv(here("box_search.csv"), show_col_types = FALSE)
}

# find all file names with log in it
files_all <- 
  dir_ls(box_search$folder,
         regexp  = "^[^~]*\\.(xlsx)$",
         recurse = TRUE) %>%
  tibble(file_path = .,
         base      = basename(.)) %>%
    
  # extract path and file name, and year
  mutate(
    cruise_id = str_extract(file_path, 
                            "(FK|WS|WB|SV)[0-9]{4,5}"),
         year = str_extract(file_path, "[0-9]{4}"),
         year = as.numeric(year)
    )
 
# filter files after 2017, not 2019, `ignore` file, any without fknms
files_filt <-
  files_all %>%
  filter(str_detect(basename(file_path), "fknms_") &
         year > 2017 &
         year != 2019 &
         !str_detect(file_path, "ignore|blank"))

# # find all file names with log in it
# files <-
#   here("data", "metadata", "WS_all") %>%
#   dir_ls(
#   regexp = "^[^~]*log.*\\.(xlsx)$",
#   recurse = TRUE
# ) %>%
#   tibble(files = .) %>%
#   
#   # extract path and file name, and year
#   mutate(
#     path = dirname(files),
#     file = basename(files),
#     year = str_extract(path, "20[0-9]{2}")
#   ) 

# filter files after 2017, not 2019, `ignore` file, any without fknms
# files_filt <-
#   files %>%
#   filter(str_detect(basename(file), "fknms_") &
#          year > 2017 &
#          year != 2019 &
#          !str_detect(file, "ignore|blank"))

# files$file
```
# ---- Read Sheet Info ----
```{r}
files <- files_filt

recal <- tibble()

for (i in seq(nrow(files))) {
  # select sheet name with `field_logsheet`
  cli::cli_alert_info("Getting sheet info for file: {.file {files$base[i]}}")
  temp_sht <- excel_sheets(files$file_path[i]) 
  sht_num  <- which(str_detect(temp_sht, "(?i)edna") & 
                    !str_detect(temp_sht, "(?i)print"))
  
  # if (is_empty(sht_num)) {
  #   sht_num <- which(str_detect(temp_sht, "Sheet1")) 
  # } 
  
  if (is_empty(sht_num)) {
    sht_num <- menu(temp_sht, 
                    title = glue(
                      "\n-----\n\n",
                      "Which sheet contains metadata?", 
                      "\n(0 for none)"))
  }
  
  # skip if no sheet name
  if (sht_num == 0) {
    recal <- 
      bind_rows(
        recal,
        tibble(file_path = files$file_path[i]))
    next
  }
  
  # read sheet 
  temp <- read_excel(
    files$file_path[i],
    sheet        = sht_num, 
    n_max        = 5,
    col_names    = FALSE,
    .name_repair = "unique_quiet") 
  
  # row number that contains headers
  row <- which(apply(temp, 1, function(x) any(grepl("(?i)MM:DD:YY", x))))
  
  if (is_empty(row) || is.na(row)) {
    View(temp)
    row <- readline("Which line is the header? ") %>%
      as.numeric()
  }
  
  # skip if no row info
  if (is_empty(row) || is.na(row)) {
    recal <-
      bind_rows(recal, 
                tibble(file_path    = files$file_path[i], 
                       sht_num = sht_num))
    next
  }
  
  # get last column to read
  # either `notes` or `collector`
  last_c <- which(grepl("(?i)notes|(?i)collector", temp[row,])) %>%
    max()
  
  recal <- 
    bind_rows(
      recal,
      tibble(
        file_path = files$file_path[i],
        sht_num = sht_num,
        row     = row,
        last_c  = last_c
      )
    )
}

# joins recal and files
files <- recal %>%
  drop_na(everything()) %>%
  left_join(files, by = "file_path")
```
# ---- Read Files ----
```{r}
files <-
  files %>%
  mutate(
    data = pmap(
      list(file_path, sht_num, row, last_c), 
      function(.x, .y, .z, .l) {
        # load data
        # select sheet, skip number of lines to sample 1, stop columns after
        # `notes` or `collector`, remove NA values, clean names
        temp <- read_xlsx(
          path         = .x,
          sheet        = .y,
          skip         = .z - 1,
          range        = cell_cols(c(NA, .l)),
          .name_repair = janitor::make_clean_names,
          na           = na_skip
        ) %>%
          mutate(
            notes = as.character(notes)
          ) 
        
        if (isTRUE(any(str_detect(temp, "Did not take any")))) {
          temp <- filter(temp, str_detect(notes, "(?i)did not"))
        }
        
        return(temp)
      }
    )
  )



```


```{r todo-delete}
# # file_i <- list()
# 
# recal <- data.frame(file = NA, sht_name = NA, row = NA, last_c = NA)
# 
# for (i in seq(nrow(files))) {
#   # for (i in 6:8) {
#   
#   
#   cli::cli_alert_info("Reading file: {.file {files$file[i]}}")
#   temp_sht <- excel_sheets(files$files[i]) 
#   
#   # detect enda sheet, search if not
#   sht_name <- str_which(temp_sht, "(?i)edna")
# 
#   if (length(sht_name) > 1 || length(sht_name) < 1 || is.na(sht_name)) {
#     cli::cli_alert_info("Couldn't find a sheet with {.code eDNA}")
#     cli::cli_inform("Which sheet is it?")
#     cli::cli_ol(temp_sht)
#     sht_name <- readline("") %>% as.numeric()
#   }
#   
#   if (is.na(sht_name)) {
#     cli::cli_alert_danger("Skipping file: {.file {files$file[i]}}")
#     next
#     }
#   
#   # read file for headers
#   temp <- read_excel(files$files[i],
#              sheet = sht_name, 
#              n_max = 5,
#              col_names = F) 
# 
#   name <- files$file[i]
#   
#   # detect row that has `sample` from 1st column
#   row <- str_which(temp$...1, "(?i)sample")
#   
#   if (length(row) == 0 || is.na(row)) {
#     cli::cli_alert_info("Couldn't find a row with {.code sample}")
#     cli::cli_inform("Which row is it?")
#     cli::cli_ol(temp$...1)
#     row <- readline("") %>% as.numeric()
#   } 
#   
#   if (is.na(row)) {
#     cli::cli_alert_danger("No row with {.code sample}")
#     cli::cli_alert_danger("Skipping file: {.file {files$file[i]}}")
#     next
#     }
#   
#   # final column
#   if (!is.na(row)) {
#     last_c <- str_which(temp[row, ], "(?i)notes")
#   }
#   
#   # file_i[[name]] <- as.character(temp[row,]) 
#   
#   recal[i,] <- data.frame(file = files$file[i], 
#                      # temp_sht[sht_name], 
#                      sht_name, 
#                      as.numeric(row), 
#                      as.numeric(last_c)
#                      )
#    
# }
# 
# files <- recal %>%
#   drop_na(file) %>%
#   left_join(files, ., by = "file")

# -- orignally separate chunks
# # header <- tibble(`names(temp)` = NA)
# store_edna <- list()
# 
# files <- files %>%
#   drop_na(sht_name)
# 
# na_skip <- c("NA", "Skipped", "skipped", "na", "n/a", "n./a", "n.a", "Flow", 
#              stringi::stri_dup("-", 1:20))
# 
# 
# for (i in seq(nrow(files))) {
#   cli::cli_alert_info("Reading file: {.file {files$file[i]}}")
#   temp <- read_xlsx(
#     files$files[i],
#     sheet        = files$sht_name[i],
#     # n_max      = 30,
#     skip         = files$row[i] - 1,
#     .name_repair = janitor::make_clean_names,
#     na           = na_skip
#   )   %>%
#   select(1:files$last_c[i]) # %>%
#   
#   if (nrow(drop_na(temp, sample)) < 3 ) next
#   
#   if (is.logical(temp$depth_m)) {
#     temp <- temp %>%
#     mutate(depth_m = 1)
#   }
#   {
#     #     type_convert() %>%
#   #   mutate(
#   #     notes = as.character(notes)
#   #   )
#   
#  
#   # if (basename(files[i]) == "fknms_sample_logsheet_OCT2017.xlsx") {
#   #   temp %<>%
#   #   mutate(vol_ml = strsplit(as.character(vol_ml), "&")) %>%
#   #     unnest(vol_ml) %>%
#   #     mutate(vol_ml = str_trim(vol_ml)) %>%
#   #     type_convert()
#   # }
# 
#   # if (basename(files[i]) == "fknms_logsheet_OCT2018.xlsx") temp %<>%
#   # rename("sample_collection_time_gmt" = time_gmt)
#   # 
#   # if (basename(files[i]) == "fknms_sample_logsheet_07_08_2021.xlsx") temp %<>% 
#   #   replace_na(list(depth_m = 1))
# 
#   
#   # store_edna$fknms_sample_logsheet_07_08_2021.xlsx %>%
#   # replace_na(list(depth_m = 1))
#     }
#   
#   name               <- files$file[i]
#   store_edna[[name]] <- temp
# 
#   # header <- bind_rows(header, as.data.frame(names(temp)))
#   
# }
# 
# # ---- fix 2 files ----
# # causes errors with merging becaue of column type being different
# # errors with typing on the user level
# # Oct 2018
# store_edna$fknms_logsheet_OCT2018.xlsx %<>%
#   filter(!is.na(vol_ml)) %>%
#   # select(mm_dd_yy) %>%
#   mutate(
#     mm_dd_yy = janitor::excel_numeric_to_date(as.numeric(mm_dd_yy)),
#     mm_dd_yy = as.POSIXct(mm_dd_yy)
#   ) %>%
#     fill(everything()) %>%
#   mutate(
#     sample = case_when(
#       str_detect(sample, "(?i)blank") ~ sample,
#       TRUE ~ str_to_upper(sample)),
#     across(lon:lat, ~ case_when(
#       str_detect(sample, "(?i)blank") ~ NA_real_,
#       TRUE ~ .x
#     ))
#   )
# 
# # Oct 2022
# store_edna$fknms_sample_logsheet_10_2022.xlsx %<>%
#   filter(!is.na(vol_ml)) %>%
#   mutate(
#     max_depth_m = str_replace(max_depth_m, "\\.\\.", "\\."),
#     max_depth_m = as.numeric(max_depth_m)
#   )

```
# ---- Check Mismatched Column Types or Names ----
```{r mismatch}
mismatch <- t(janitor::compare_df_cols(files$data, return = "mismatch"))        
rownames(mismatch) <- c(NA, tools::file_path_sans_ext(files$base))
                         
mismatch

# # examine issue columns by entering the name of the file and the column that 
# # might be problematic
# # bad <- 
# (files %>%
#   filter(str_detect(file_path, ""<enter-bad-base-file-name>"")) %>%
#   pull(data))[[1]]  %$% 
#   unique(<variable-to-check>) 
# 
# # open file in excel if on windows?
# files %>%
#   filter(str_detect(file_path, ""<enter-bad-base-file-name>"")) %$% 
#   shell.exec(file_path)
```
# ---- Unnest Metadata and Format ----
```{r}
data_all <- 
  files %>%
  select(-c(file_path:base)) %>%
  unnest(data) %>%
  filter(!if_all(mm_dd_yy:vol_ml, is.na) &
         mm_dd_yy > as_date("2015-01-01")) %>%
  mutate(
    time_gmt = hms::as_hms(time_gmt),
    year     = year(mm_dd_yy),
    month    = month(mm_dd_yy, label = TRUE),
    day      = day(mm_dd_yy),
    station  = str_to_upper(station),
    .before  = station
    ) %>%
  mutate(
    depth_m   = case_when(
      str_detect(sample, "(?i)blank") 
      | str_detect(station, "(?i)blank") ~ 0,
      is.na(depth_m) ~ 1,
      TRUE ~ depth_m),
    sample    = str_remove(sample, "\\*"),
    replicate = str_extract(sample, "(?i)[a-c]$|[1-6]$"), 
    replicate = str_to_upper(replicate),
    filter_type = "sterivex",
    .after    = sample
  ) 

# save current sheet
if (FALSE) {
  store_merg %>%
  write_csv(
    here("data", "metadata", 
         glue("edna_metadata",
          # time of save, so you don't overwrite
          format(Sys.time(), '_%Y%m%d_%H%M%S'),
          ".csv")),
    na = ""
    )
}
```

# Probably Delete
```{r todo-delete2}
# store_merg <- 
  # reduce(store_edna, full_join) %>%
  # filter(!is.na(mm_dd_yy) & !is.na(vol_ml)) %>%
  
  # mutate(
  #   time_gmt = hms::as_hms(time_gmt),
  #   year     = year(mm_dd_yy),
  #   month    = month(mm_dd_yy, label = TRUE),
  #   day      = day(mm_dd_yy),
  #   station  = str_to_upper(station),
  #   .before  = station
  #   ) %>%
  # fill(collector)  %>%
  # group_by(station) %>%
  # fill(lat, lon) %>%
  # ungroup()
# 
# blank <- store_merg %>%
#   # filter(!is.na(mm_dd_yy) & !is.na(vol_ml)) %>%
#   filter(str_detect(sample, "(?i)blank") | 
#            str_detect(station, "(?i)blank")) %>%
#   
#   mutate(time_gmt = hms::as_hms(time_gmt))
# 
# store_merg <-
#   store_merg  %>%
#   filter(!(str_detect(sample, "(?i)blank") | 
#              str_detect(station, "(?i)blank"))) %>%
#   
#   mutate(
#     cruise_id = case_when(
#         between(ymd(mm_dd_yy), ymd("2018-10-01"), ymd("2018-10-20")) ~ "WS18285",
#         TRUE ~ str_split(sample, pattern = "-", simplify = TRUE)[,1]), 
#     .before = everything()
#   ) %>%
#   
#   full_join(., blank) %>%
#   arrange(mm_dd_yy) %>%
#   fill(cruise_id) %>%
  # mutate(
  #   depth_m = case_when(
  #     str_detect(sample, "(?i)blank") | str_detect(station, "(?i)blank") ~ 0,
  #     is.na(depth_m) ~ 1,
  #     TRUE ~ depth_m),
  #   sample = str_remove(sample, "\\*"),
  #   replicate = str_sub(sample, -1L, -1L), 
  #   replicate = if_else(str_detect(replicate, "(?i)[A-C1-6]"),
  #                       replicate, NA_character_),
  #   .after = sample
  # )

# for (i in 1:nrow(test)) {
#   View(test$data[[i]], test$cruise_id[i])
# }

# if (FALSE) {
#   store_merg %>%
#   write_csv(
#     paste0(here::here("data", "metadata", "edna_metadata"),
#           # time of save, so you don't overwrite
#           format(Sys.time(), '_%Y%m%d_%H%M%S'),
#           ".csv"),
#     na = ""
#     )
# }
# 
# 
# read_csv(
#     here::here("data", "metadata", "edna_metadata_20220916_103458.csv"),
# )
# 
# store_merg %>%
#   count(cruise_id)
```
# ---- Merge to Enrique's Format ----
```{r}
master_file <-
suppressWarnings(master <- 
  here("data", "metadata") %>%
  dir_ls(., regex = "master_up-to-2022") %>%
  read_xlsx(., 
            sheet = "eDNA2",
            .name_repair = "unique_quiet"))


{
  cat("\nData:\n")
  cat(names(data_all), sep = ", ")
  cat("\n\nMaster:\n")
  cat(names(master), sep = ", ")
}

finals <- 
  data_all %>%
  mutate(
    across(c(everything(), 
             -time_gmt, 
             -vol_ml), 
           as.character)) %>%
  select(-sample_n) %>%
  
  # rename to fit master
  rename(
    "Notes"       = "notes",
    "sample_id"   = "sample",
    "long"        = "lon",
    "lat"         = "lat",
    "depth"       = "depth_m",
    "Replicate"   = "replicate",
    "filter type" = "filter_type"
  ) 

finals <- bind_rows(master, finals)

if (FALSE) {
  finals %>%
  xlsx::write.xlsx(.,
    here("data", "metadata", glue("master_up-to-",
                                  sort(finals$mm_dd_yy, 
                                       decreasing = TRUE)[1] %>%
                                    as_date() %>%
                                    format("%b-%Y"), 
                                  ".xlsx")), 
    sheetName = "eDNA2", 
    append    = TRUE, 
    showNA    = FALSE,
    row.names = TRUE
  )
}
```

```{r delete-idk}

# 
# store_merg %>%
#   filter(!is.na(date_mm_dd_yy), !is.na(sample_collection_time_gmt)) %>%
#   # filter(sample_type != "CDOM", is.na(vol_ml))
#   group_by(sample_type) %>%
#   distinct() %>%
#   summarise(total = n())
#   
# test <- store_merg %>%
#   filter(!is.na(date_mm_dd_yy), !is.na(sample_collection_time_gmt)) %>%
#   # filter(sample_type != "CDOM", is.na(vol_ml))
#   group_by(sample_type) %>%
#   distinct()
# # %>%
#   # summarise(total = n())
# 
# store_merg %>% 
#   # arrange(date_mm_dd_yy)
#   filter(date_mm_dd_yy <= as_date("2019-07-19")) %>%
#   group_by(sample_type) %>%
#   
#   summarise(n = n())
# 
# 
# 
# store_merg %>%
#   filter(sample_type == "Chl-a", 
#          !is.na(vol_ml),
#          date_mm_dd_yy != as_date("1899-12-31 00:00:00")
#          ) %>%
#   distinct(identifier, .keep_all = T) %>%
#   arrange(date_mm_dd_yy)

```
# ---- Dec 2022 and Jan 2023 ----
```{r}
# meta <-
#   here(cloud_dir, "years", c("2022", "2023"))  %>%
#   fs::dir_ls(
#   recurse = TRUE,
#   regexp = "sample.*(12_2022|01_2023)"
# ) %>%
#   tibble(files = .) %>%
#   filter(!str_detect(files, "ignore")) %>%
#   mutate(
#     base = basename(files),
#     cruise_id = str_extract(files, "WS[0-9]{5}"),
#     info = map(files,
#                ~ read_xlsx(.x,
#                            .name_repair = janitor::make_clean_names,
#                            sheet = "eDNA",
#                            na = c(na_skip, ":"),
#                            # col_types = c("mm_dd_yy" = "date")
#                            # range = cell_cols(c(NA, "notes"))
#                            )  %>%
#                     select(-c(x:last_col())) %>%
#                     filter(!if_all(1:3, is.na) &
#                            !if_all(c(vol_ml, lat, lon), is.na)) #%>%
#                     # mutate(mm_dd_yy = janitor::excel_numeric_to_date(mm_dd_yy))
#                )
#   ) %>%
#   unnest(info)
# 
# 
# c("cruise_id", "station", "sample_id", "Extraction_no", "DNA_extr_kit", "mm_dd_yy", "year", "month", "day", "time_gmt", "lat", "long", "depth", "max_depth_m", "Replicate", "vol_ml", "filter type", "DNA_conc_ng_ul", "12s_sequ", "16S_sequ", "18S_sequ", "COI_sequ", "28S_sequ", "Date extracted", "Notes", "Manuscript", "collector")
```

```{r}
# match_var <- c("station", "year", "month", "day", "Notes" = "notes", 
#                "long" = "lon", "lat" = "lat", "depth" = "depth_m", 
#                "Replicate" = "replicate", "filter type" = "filter_type")
# 
# names(meta)
# names(master)
#  finals <- 
#   meta %>%
#   select(-c(1:2)) %>%
#     rename("max_depth_m" = max_depth) %>%
#     
#      mutate(
#     depth_m = case_when(
#       str_detect(sample, "(?i)blank") | str_detect(station, "(?i)blank") ~ 0,
#       is.na(depth_m) ~ 1,
#       TRUE ~ depth_m),
#     sample = str_remove(sample, "\\*"),
#     replicate = str_sub(sample, -1L, -1L), 
#     replicate = if_else(str_detect(replicate, "(?i)[A-C1-6]"),
#                         replicate, NA_character_),
#     .after = sample
#   ) %>%
#   mutate( 
#     time_gmt = hms::as_hms(time_gmt),
#     year = year(mm_dd_yy),
#     month    = month(mm_dd_yy, label = TRUE),
#     day      = day(mm_dd_yy),
#     station  = str_to_upper(station),
#     .after = mm_dd_yy
#     ) %>%
#       
#   
#   mutate(
#     filter_type = "sterivex",
#     across(c(everything(), -time_gmt, -vol_ml), as.character)) %>%
#   select(-sample_n) %>%
#   full_join(master, ., by = match_var) %>%
#   # slice(1000:nrow(finals))
#   relocate(mm_dd_yy, .before = year) %>%
#   relocate(time_gmt, .after = day) %>%
#   relocate(cruise_id, .before = 1) %>%
#   relocate(sample_id = sample, .after = station) %>%
#   relocate(vol_ml, .after = Replicate) %>%
#   relocate(max_depth_m, .after = depth) %>%
#   filter(
#     (str_detect(year, "2022") & str_detect(month, "Dec") )|
#     (str_detect(year, "2023") & str_detect(month, "Jan")) 
#   ) 
```


```{r}
finals %>%
  xlsx::write.xlsx(.,
    here("data", "metadata", "jan_dec.xlsx"), sheetName = "eDNA2", append = TRUE, showNA = FALSE
  )
  
```

